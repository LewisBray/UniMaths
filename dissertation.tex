\documentclass[a4paper,12pt,draft]{report}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}

\setlength{\unitlength}{10mm}
\renewcommand{\baselinestretch}{1.5}

\begin{document}

\title{Semiclassical Asymptotics for the Heat Equation Using the Stochastic Elementary Formula}
\author{Lewis J. Bray}

\maketitle

\tableofcontents

\chapter{Introduction}

We let $u^\mu : \mathbb{R}^n \times [0, \infty) \to \mathbb{R}$ be the solution to the heat equation,
$$
\left\{
\begin{aligned}
\frac{\partial u^\mu}{\partial t}(x, t) & = \frac{\mu^2}{2}\Delta u^\mu(x, t) + \frac{1}{\mu^2}V(x)u^\mu(x, t),\\
u^\mu(x, 0) & = T_0(x)\exp\left(-\frac{S_0(x)}{\mu^2}\right),
\end{aligned}
\right.
$$
where $V$ is some potential, $S_0$, $T_0$, $V : \mathbb{R}^n \to \mathbb{R}$ are independent of our diffusivity term $\mu > 0$ and are sufficiently well-behaved to guarantee the existence of a unique, smooth and positive solution $u^\mu$.  If $B_t$ is an $n$-dimensional Brownian motion on a probability space $(\Omega, \mathscr{F}, \mathbb{P})$ and $B_t^\mu = x + \mu B_t$, for $x \in \mathbb{R}^n$, then the Feynman-Kac representation of the solution is given by,
$$
u^\mu(x, t) = \mathbb{E}\left(T_0(B_t^\mu)\exp\left(-\frac{1}{\mu^2}S_0(B_t^\mu) + \frac{1}{\mu^2}\int_0^tV(B_s^\mu)\,\mathrm{d}s\right)\right)
$$
where $\mathbb{E}$ is the expectation with respect to the Wiener measure $\mathbb{P}$.

The idea for this formula came from the Schr$\ddot{\text{o}}$dinger equation (for a particle of unit mass) in quantum mechanics,
$$
i\hbar\frac{\partial\psi}{\partial t}(x, t) = -\frac{\hbar^2}{2}\Delta\psi(x, t) + V(x)\psi(x, t) = H\psi(x, t)
$$
where $H$ is the Hamiltonian operator, $i$ is the imaginary unit, $\hbar$ is Planck's constant and $\psi$ is the wave function.  In 1948, Richard Feynman proposed that the solution to Schr$\ddot{\text{o}}$dinger equation be given by a sum over all possible histories of the particle.  Later, Mark Kac realised that by using the formal substitution $i\hbar \mapsto \mu^2 > 0$, he could consider the heat equation instead and was able to define a rigorous path integral over all the possible paths of the system with respect to the Wiener measure.  This integral became known as the Feynman-Kac formula.  The aim of this paper is to explore the semiclassical limit of $u^\mu$ as $\mu \to 0$, inspired by the semiclassical limit of the Schr$\ddot{\text{o}}$dinger equation.

In Chapter 2, using the Feynman-Kac formula as a basis, we shall derive the stochastic elementary formula,
$$
u^\mu(x, t) = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(T_0(X_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\Delta S(X_s^\mu, t - s)\right)\,\mathrm{d}s\right)
$$
where $S$ is Hamilton's principal function and $X_s^\mu$ satisfies,
$$
\left\{
\begin{aligned}
\mathrm{d}X_s^\mu & = -\nabla S(X_s^\mu, t - s)\,\mathrm{d}s + \mu\,\mathrm{d}B_s, X_0^\mu = x, \\
X_0^\mu & = x, \hspace{0.3cm} s \in [0, t].
\end{aligned}
\right.
$$
This formula originates from the works of Elworthy and Truman \cite{SEF1} - \cite{SEF4} and gives us a tool for investigating the asymptotic behaviour of $u^\mu$ as $\mu \to 0$ using the associated classical mechanics.  We define our classical mechanical flow map,
$$
\left\{
\begin{aligned}
\ddot{\Phi}_t(x) & = -\nabla V(\Phi_t(x)), \hspace{0.3cm} t \in [0, \tilde{T}), \hspace{0.3cm} \tilde{T} > 0,\\
\dot{\Phi}_0(x) & = \nabla S_0(x), \\
\Phi_0(x) & = x.
\end{aligned}
\right.
$$
Using this we will see that we can derive the asymptotic behaviour of $u^\mu$ showing that,
$$
\lim_{\mu \to 0} \exp\left(\frac{S(x, t)}{\mu^2}\right)u^\mu(x, t) = T_0(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}.
$$
This can also be extended to include higher order terms in $\mu^2$.

In the final chapter, we will expand on the ideas of Chapter 2 and consider a heat equation with a vector potential $\mathbf{a}(x, t)$ given by,
$$
\left\{
\begin{aligned}
& \frac{\partial u^\mu}{\partial t}(x, t) = \frac{\mu^2}{2}\Delta u^\mu(x, t) + \mathbf{a}(x, t)\cdot\nabla u^\mu(x, t) + \frac{1}{\mu^2}\bar{V}(x, t)u^\mu(x, t),\\
& u^\mu(x, 0) = T_0(x)\exp\left(-\frac{S_0(x)}{\mu^2}\right),
\end{aligned}
\right.
$$
where $\bar{V}(x, t) = \frac{1}{2}\|\mathbf{a}(x, t)\|^2 + \frac{\mu^2}{2}\nabla\cdot\mathbf{a}(x, t) + V(x)$ is our new time dependent potential.  The inclusion of a vector potential is based on the Schr$\ddot{\text{o}}$dinger equation for a charged particle in an electromagnetic field.  The Hamiltonian for a particle of unit mass and unit charge acted on by a vector potential $\mathbf{a}$ and an electric potential $V$ is given by,
$$
H(\mathbf{q}, \mathbf{p}, t) = \frac{1}{2}\|\mathbf{p} - \mathbf{a}(\mathbf{q}, t)\|^2 + V(\mathbf{q}).
$$
Switching to quantum mechanics we make the operator substitutions, $\mathbf{p} \mapsto \frac{\hbar}{i}\nabla$ and $\mathbf{q} \mapsto x$, where $x$ denotes the operator "multiply by $x$".  Then,
\begin{align}
i\hbar\frac{\partial\psi}{\partial t}(x, t) & = H\psi(x, t)\nonumber\\
& = \frac{1}{2}\left\|\frac{\hbar}{i}\nabla - \mathbf{a}(x, t)\right\|^2\psi(x, t) + V(x)\psi(x, t)\nonumber\\
& = -\frac{\hbar^2}{2}\Delta\psi(x, t) + i\hbar\mathbf{a}(x, t)\cdot\nabla\psi(x, t)\nonumber\\
& \hspace{0.5cm} + \left(\frac{1}{2}\|\mathbf{a}(x, t)\|^2 + \frac{1}{2}i\hbar\nabla\cdot\mathbf{a}(x, t) + V(x)\right)\psi(x, t).\nonumber
\end{align}
To get to the heat equation with vector potential we make again the formal substitution $i\hbar \mapsto \mu^2 > 0$.  We can then use the same methods as before, now using the classical mechanics,
$$
\left\{
\begin{aligned}
\ddot{\Phi}_t(x) & = -\nabla V(\Phi_t(x)) - \frac{\partial \mathbf{a}}{\partial t}(\Phi_t(x), t) - (\nabla \times \mathbf{a}(\Phi_t(x), t))\times\dot{\Phi}_t(x),\\
\dot{\Phi}_0(x) & = \nabla S_0(x) - \mathbf{a}(x, 0),\\
\Phi_0(x) & = x,
\end{aligned}
\right.
$$
as shown in \cite{ANSRAT}.






\chapter{The Feynman-Kac Formula}

The first chapter introduces the Feynman-Kac formula which is a representation of the solution to the initial value problem,
\begin{equation}
\left\{
\begin{aligned}
\frac{\partial u}{\partial t}(x, t) & = \frac{1}{2}\sum_{i, j = 1}^n a_{ij}(x)\frac{\partial^2 u}{\partial x_i \partial x_j}(x, t) + \sum_{i = 1}^n b_i(x)\frac{\partial u}{\partial x_i}(x, t) + V(x)u(x, t)\\
& = Lu(x, t) + V(x)u(x, t), \hspace{0.3cm} x \in \mathbb{R}^n,\\ \label{CP}
u(x, 0) & = f(x),
\end{aligned}
\right.
\end{equation}
where $L$ is the operator,
$$
L = \frac{1}{2}\sum_{i, j = 1}^n a_{ij}(x)\frac{\partial^2}{\partial x_i \partial x_j} + \sum_{i = 1}^n b_i(x)\frac{\partial}{\partial x_i}.
$$
\assumption
{
We assume that:
\begin{enumerate}
\item The functions $a_{ij}, b_i, V : \mathbb{R}^n \to \mathbb{R}$ are bounded and globally Lipschitz.
\item The function $f : \mathbb{R}^n \to \mathbb{R}$ is bounded and continuous.
\item The matrix $A = (a_{ij}(x))$ can be represented as the product of an $n \times n$ matrix $\sigma(x)$ and its transpose $\sigma^*(x)$ and $A$ itself is positive definite.
\end{enumerate}
}

Throughout this chapter we follow Freidlin \cite{Freidlin} (pages 117-129) and begin by considering the stochastic differential equation (later referred to as an S.D.E.),
\begin{equation}
\left\{
\begin{aligned}
\mathrm{d}X_t^x & = \sigma(X_t^x)\,\mathrm{d}B_t + b(X_t^x)\,\mathrm{d}t,\\ \label{SDE}
X_0^x & = x \in \mathbb{R}^n,
\end{aligned}
\right.
\end{equation}
where $B_t$ is an n-dimensional Brownian Motion, $b$ is the n-dimensional vector with elements $b_i$ and $X_t^x$ is a stochastic process defined on a probability space $(\Omega, \mathscr{F}, \mathbb{P})$ with filtration $(\mathscr{F}_t)_{t \in [0, \infty)}$.
\definition
{
Let $X_t^x(\omega)$, $t \ge 0$ be an n-dimensional stochastic process satisfying \eqref{SDE} on a probability space $(\Omega, \mathscr{F}, P)$ with filtration $(\mathscr{F}_t)_{t \in [0, \infty)}$.  The pair $(X_t^x, P)$ is called a \emph{Markov family} if, for all $\Gamma \in \mathscr{B}^n$:
\begin{enumerate}
\item $P\{X_t^x \in \Gamma\} = p(t , x, \Gamma)$ is a $\mathscr{B}^n$-measurable function in $x \in \mathbb{R}^n$.
\item $p(0, x, \mathbb{R}^n\smallsetminus\{x\}) = 0$.
\item If $s \in [0, t]$, then $P\{X_t^x \in \Gamma | \mathscr{F}_s\} = p(t - s, X_s^x, \Gamma)$ $P$ - a.s.
\end{enumerate}
where $\mathscr{B}^n$ denotes the Borel $\sigma$-algebra on $\mathbb{R}^n$.
}
\definition
{
Let $C_{0, \infty}(\mathbb{R}^n$) be the space of all continuous functions on $[0, \infty)$ that take values in $\mathbb{R}^n$ and let $\Sigma$ be the $\sigma$-algebra of all the cylinder sets of $C_{0, \infty}(\mathbb{R}^n)$. On the measurable space $(C_{0, \infty}(\mathbb{R}^n), \Sigma)$, we define a family of probability measures $P_x$, for $x \in \mathbb{R}^n$ by $P_x\{\Sigma\} = P\{X_\cdot^x \in \Sigma\}$, where $X_\cdot^x$ satisfies \eqref{SDE}.  We also define a random process $X_t(\omega) = \omega_t$, for all $\omega \in C_{0, \infty}(\mathbb{R}^n)$.  The collection $(X_t(\omega), P_x)$ is called the \emph{Markov process} corresponding to \eqref{SDE}.
}

By Assumption 1, $(X_t^x)_{t \ge 0}$ defines a Markov family and a corresponding Markov process $(X_t, P_x)$.  Along with our Markov family, we introduce a family of operators $(\tilde{T}_t^V)_{t \ge 0}$ defined by,
$$
\tilde{T}_t^Vf(x) = \mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right), \hspace{0.3cm} f \in S
$$
where $S$ is taken to be the Banach space of all bounded and measurable functions in $\mathbb{R}^n$ with the norm $\|f\|_\infty = \sup_{x \in \mathbb{R}^n}|f(x)|$.
\lemma
{
Each $\tilde{T}_t^V$ is linear, bounded and preserves non-negativity.  Moreover, the family $(\tilde{T}_t^V)_{t \ge 0}$ is a convolution semi-group.
}
\proof
{
To show $\tilde{T}_t^V$ is linear, let $f, g \in S$ and $\lambda, \mu \in \mathbb{R}$, then,
\begin{align}
\tilde{T}_t^V(\lambda f + \mu g)(x) & = \mathbb{E}\left((\lambda f + \mu g)(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right)\nonumber\\
& = \lambda \mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right)\nonumber\\
& \hspace{0.5cm} + \mu \mathbb{E}\left(g(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right)\nonumber\\
& = \lambda\tilde{T}_t^Vf(x) + \mu\tilde{T}_t^Vg(x)\nonumber.
\end{align}
Since $V$ is bounded, $\int_0^tV(X_s^x)\,\mathrm{d}s$ is bounded and in turn $\exp\left(\int_0^tV(X_s^x)\,\mathrm{d}s\right)$ is bounded too.  The function $f$ itself is bounded and since the expectation of anything bounded is bounded also, we have that $\tilde{T}_t^V$ is bounded for all $f \in S$.  Next, let $f(x) \ge 0$, for all $x \in \mathbb{R}^n$, then clearly,
$$
f(X_t)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right) \ge 0.
$$
Since expected values are non-negative preserving by nature, the final property of $\tilde{T}_t^V$ is proven.
Next, to show that $(\tilde{T}_t^V)_{t \ge 0}$ is a convolution semi-group,
\begin{align}
\tilde{T}_{t + s}^Vf(x) & = \mathbb{E}\left(f(X_{t + s}^x)\exp\left(\int_0^{t + s} V(X_u^x)\,\mathrm{d}u\right)\right)\nonumber\\
& = \mathbb{E}\left(f(X_{t + s}^x)\exp\left(\int_0^t V(X_u^x)\,\mathrm{d}u + \int_t^{t + s} V(X_u^x)\,\mathrm{d}u\right)\right)\nonumber\\
& = \mathbb{E}\left(\exp\left(\int_0^t V(X_u^x)\,\mathrm{d}u\right)f(X_{t + s}^x)\exp\left(\int_t^{t + s} V(X_u^x)\,\mathrm{d}u\right)\right).\nonumber
\end{align}
We introduce the time-shift operator $\theta_t$ which is defined as $\theta_tg(x, s) = g(x, t + s)$, for $t \in \mathbb{R}$,
$$
\tilde{T}_{t + s}^Vf(x) = \mathbb{E}\left(\exp\left(\int_0^t V(X_u^x)\,\mathrm{d}u\right)\theta_t\left(f(X_s^x)\exp\left(\int_0^s V(X_u^x)\,\mathrm{d}u\right)\right)\right).
$$
Finally, using the independence properties of Markov Processes,
\begin{align}
\tilde{T}_{t + s}^Vf(x) & = \mathbb{E}\left(\exp\left(\int_0^s V(X_u^x)\,\mathrm{d}u\right)\right)\mathbb{E}\left((f(X_s^{X_t})\exp\left(\int_0^s V(X_u^{X_t})\,\mathrm{d}u\right)\right)\nonumber\\
& = \tilde{T}_t^V(\tilde{T}_s^Vf(x)).\nonumber
\end{align}

\qedhere
}

Let $\Theta$ and $\tilde{\Theta}$ denote the infinitesimal generators of the process $(X_t, P_x)$ and the operator $\tilde{T}_t^V$ respectively, given explicitly by,
$$
\Theta f = \lim_{t \searrow 0}\frac{T_tf - f}{t}, \hspace{0.5cm} \tilde{\Theta}f = \lim_{t \searrow 0}\frac{\tilde{T}_t^Vf - f}{t}
$$
where $T_tf = \mathbb{E}(f(X_t^x))$.  We let $D_\Theta$ denote the domain of $\Theta$ and $D_{\tilde{\Theta}}$ denote the domain of $\tilde{\Theta}$.  $D_\Theta$ and $D_{\tilde{\Theta}}$ are defined as the set of all functions $f \in S$ such that the limits $\Theta f$ and $\tilde{\Theta}f$ exist, respectively.
\lemma
{
The domains $D_\Theta$ and $D_{\tilde{\Theta}}$ coincide and
$$
\tilde{\Theta} f(x) = \Theta f(x) + V(x)f(x), \hspace{0.3cm} \text{for} \hspace{0.15cm} f \in D_\Theta = D_{\tilde{\Theta}}.
$$
}
\proof
{
We first note that,
$$
\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right) = 1 + \int_0^t V(X_s^x)\,\mathrm{d}s + o(t)
$$
where we use the little-$o$ notation as defined in \cite{NGDB}.

and then by direct computation,
\begin{align}
& \frac{\tilde{T}_t^Vf(x) - f(x)}{t}\nonumber\\
& = \frac{1}{t}\left(\mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right) - f(x)\right)\nonumber\\
& = \frac{1}{t}\left(\mathbb{E}(f(X_t^x)) + \mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right) + o(t) - f(x)\right)\nonumber\\
& = \frac{\mathbb{E}(f(X_t^x)) - f(x)}{t} + \mathbb{E}\left(f(X_t^x)\frac{1}{t}\int_0^t V(X_s^x)\,\mathrm{d}s\right) + \frac{o(t)}{t}\nonumber\\
& = \frac{T_tf(x) - f(x)}{t} + \mathbb{E}\left(f(X_t^x)\frac{1}{t}\int_0^t V(X_s^x)\,\mathrm{d}s\right) + \frac{o(t)}{t}.\nonumber
\end{align}
From this it is trivial to see that $D_\Theta = D_{\tilde{\Theta}}$.  Next, by taking the limit as $t \searrow 0$,
\begin{align}
\tilde{\Theta} f(x) & = \lim_{t \searrow 0}\frac{\tilde{T}_t^Vf(x) - f(x)}{t}\nonumber\\
& = \lim_{t \searrow 0}\frac{T_tf(x) - f(x)}{t} + \lim_{t \searrow 0}\mathbb{E}\left(f(X_t^x)\frac{1}{t}\int_0^t V(X_s^x)\,\mathrm{d}s\right) + \lim_{t \searrow 0}\frac{o(t)}{t}.\nonumber
\end{align}
Thus, by dominated convergence,
\begin{align}
\tilde{\Theta} f(x) & = \Theta f(x) + \mathbb{E}\left(\lim_{t \searrow 0}f(X_t^x)\frac{1}{t}\int_0^t V(X_s^x)\,\mathrm{d}s\right)\nonumber\\
& = \Theta f(x) + \mathbb{E}\left(\left(\lim_{t \searrow 0}f(X_t^x)\right)\left(\lim_{t \searrow 0}\frac{1}{t}\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right)\nonumber\\
& = \Theta f(x) + \mathbb{E}(f(x)V(x))\nonumber\\
& = \Theta f(x) + V(x)f(x).\nonumber
\end{align}
Note that the product limit above can be taken since $f$ and $V$ are bounded.

\qedhere
}

The following theorem provides a step forward in proving the Feynman-Kac formula.
\theorem
{
Along with Assumption 1, we assume that $f$ has bounded and uniformly continuous partial derivatives up to and including the second order.  Then $f \in D_\Theta$ and $\Theta = L$.
}
\proof
{
First we note that due to the definition $A(x) = \sigma(x)\sigma^*(x)$ we get in index notation the elements of $A$ are given by $a_{ij} = \sigma_{ik}\sigma_{jk}$ where we use the Einstein summation convention and $\sigma_{ij}$, $i, j = 1, \dots, n$ are elements of $\sigma(x)$.  Next, we define $Y_t^x = f(X_t^x)$ and apply It$\mathrm{\hat{o}}$'s formula (see for instance \cite{Oksendal}),
$$
\mathrm{d}Y_t^x = \frac{\partial f}{\partial t}\,\mathrm{d}t + \frac{\partial f}{\partial x_i}\,\mathrm{d}X_t^i + \frac{1}{2}\frac{\partial^2 f}{\partial x_i \partial x_j}\,\mathrm{d}X_t^i\,\mathrm{d}X_t^j
$$
where $\mathrm{d}X_t^i = \sigma_{ik}\,\mathrm{d}B_t^k + b_i\,\mathrm{d}t$, i.e. the $\mathrm{i^{th}}$ component of $\mathrm{d}X_t^x$ and $\mathrm{d}B_t^k$ is the $\mathrm{k^{th}}$ component of $\mathrm{d}B_t$.  We find that,
\begin{align}
\mathrm{d}X_t^i\,\mathrm{d}X_t^j & = (\sigma_{ik}\,\mathrm{d}B_t^k + b_i\,\mathrm{d}t)(\sigma_{jk}\,\mathrm{d}B_t^k + b_j\,\mathrm{d}t)\nonumber\\
& = \sigma_{ik}\sigma_{jk}\,\mathrm{d}B_t^k\,\mathrm{d}B_t^k\nonumber\\
& = \sigma_{ik}\sigma_{jk}\,\mathrm{d}t\nonumber\\
& = a_{ij}\,\mathrm{d}t\nonumber
\end{align}
using the identites, $(\mathrm{d}t)^2 = \mathrm{d}t\,\mathrm{d}B_t^k = \mathrm{d}B_t^k\,\mathrm{d}t = 0$ and $(\mathrm{d}B_t^k)^2 = \mathrm{d}t$.  So we get,
\begin{align}
\mathrm{d}Y_t^x & = \frac{\partial f}{\partial x_i}\,(\sigma_{ik}\,\mathrm{d}B_t^k + b_i\,\mathrm{d}t) + \frac{1}{2}\frac{\partial^2 f}{\partial x_i \partial x_j}\,a_{ij}\,\mathrm{d}t\nonumber\\
& = \frac{\partial f}{\partial x_i}\,\sigma_{ik}\,\mathrm{d}B_t^k + \frac{\partial f}{\partial x_i}\,b_i\,\mathrm{d}t + \frac{1}{2}\frac{\partial^2 f}{\partial x_i \partial x_j}\,a_{ij}\,\mathrm{d}t\nonumber\\
& = \frac{\partial f}{\partial x_i}\,\sigma_{ik}\,\mathrm{d}B_t^k + \left(b_i\,\frac{\partial f}{\partial x_i} + \frac{1}{2}a_{ij}\,\frac{\partial^2 f}{\partial x_i \partial x_j}\right)\mathrm{d}t\nonumber\\
& = \frac{\partial f}{\partial x_i}\,(\sigma\mathrm{d}B_t)_i + \left(\frac{1}{2}a_{ij}\,\frac{\partial^2 f}{\partial x_i \partial x_j} + b_i\,\frac{\partial f}{\partial x_i}\right)\mathrm{d}t\nonumber\\
& = \nabla f\cdot(\sigma\mathrm{d}B_t) + Lf\,\mathrm{d}t.\nonumber
\end{align}
Integrating from $0$ to $t$ yields,
$$
f(X_t^x) - f(x) = \int_0^t \nabla f(X_s^x)\cdot(\sigma(X_s^x)\mathrm{d}B_s) + \int_0^t Lf(X_s^x)\,\mathrm{d}s\nonumber\\
$$
Finally,
\begin{align}
\Theta f(x) & = \lim_{t \searrow 0}\frac{\mathbb{E}(f(X_t^x)) - f(x)}{t}\nonumber\\
& = \lim_{t \searrow 0}\frac{1}{t}\mathbb{E}(f(X_t^x) - f(x))\nonumber\\
& = \lim_{t \searrow 0}\frac{1}{t}\left(\mathbb{E}\left(\int_0^t \nabla f(X_s^x)\cdot(\sigma(X_s^x)\mathrm{d}B_s)\right) + \mathbb{E}\left(\int_0^t Lf(X_s^x)\,\mathrm{d}s\right)\right)\nonumber
\end{align}
and by dominated convergence,
\begin{align}
\Theta f(x) & = \mathbb{E}\left(\lim_{t \searrow 0}\frac{1}{t}\int_0^t Lf(X_s^x)\,\mathrm{d}s\right)\nonumber\\
& = \mathbb{E}(Lf(x))\nonumber\\
& = Lf(x)\nonumber
\end{align}
since the expectation of a stochastic integral is zero.

\qedhere
}

\lemma
{
For every function $f \in D_{\tilde{\Theta}}$ the function,
$$
u_t(x) = \tilde{T}_t^Vf(x) = \mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right)
$$
is a solution to the initial value problem,
\begin{equation}
\left\{
\begin{aligned}
\frac{\mathrm{d}u_t}{\mathrm{d}t}(x) & = \tilde{\Theta}u_t(x),\\ \label{ACP}
u_0(x) & = f(x).
\end{aligned}
\right.
\end{equation}
}
\proof
{
First by definition,
\begin{align}
\frac{1}{s}(\tilde{T}_s^Vu_t(x) - u_t(x)) & = \frac{1}{s}(\tilde{T}_s^V\tilde{T}_t^Vf(x) - \tilde{T}_t^Vf(x))\nonumber\\
& = \tilde{T}_t^V\frac{1}{s}(\tilde{T}_s^Vf(x) - f(x))\nonumber
\end{align}
since by Lemma 1, $\tilde{T}_s^V\tilde{T}_t^V = \tilde{T}_{s + t}^V = \tilde{T}_{t + s}^V = \tilde{T}_t^V\tilde{T}_s^V$.  Next, since $f \in D_{\tilde{\Theta}}$, we know that,
$$
\lim_{s \to 0}\frac{1}{s}(\tilde{T}_s^Vf(x) - f(x))
$$
exists, and hence,
$$
\lim_{s \to 0}\frac{1}{s}(\tilde{T}_s^Vu_t(x) - u_t(x))
$$
exists also and so $u_t \in D_{\tilde{\Theta}}$.  We also have that by definition,
$$
\frac{\mathrm{d}u_t}{\mathrm{d} t} = \lim_{h \to 0}\frac{1}{h}(\tilde{T}_{t + h}^Vf(x) - \tilde{T}_t^Vf(x)) = \lim_{h \to 0}\frac{1}{h}(\tilde{T}_h^Vu_t(x) - u_t(x)).
$$
We know that this limit exists as $u_t \in D_{\tilde{\Theta}}$.  Thus, $u_t$ is differentiable with respect to $t$ and,
$$
\frac{\mathrm{d}u_t}{\mathrm{d} t} = \lim_{h \to 0}\frac{1}{h}(\tilde{T}_h^Vu_t(x) - u_t(x)) = \tilde{\Theta}u_t(x).
$$

\qedhere
}

It can be shown that the solution to \eqref{ACP} is unique in the class of functions growing at most exponentially fast, given by,
$$
K = \left\{v(x, t) : \sup_{x \in \mathbb{R}^n}v(x, t) < Ce^{\alpha t}, \hspace{0.2cm} C, \alpha < \infty\right\}.
$$
Finally we are in a position to prove the solution to \eqref{CP} as the Feynman-Kac formula.
\theorem
{
Let $u(x, t)$ be the solution to \eqref{CP}.  Also, let $u$ have uniformly continuous and bounded first and second order partial derivatives in $x$ and uniformly continuous and bounded first order partial derivative in $t$, where $t \in [0, T]$ and $x \in \mathbb{R}^n$.  Then,
\begin{equation}
u(x, t) = \mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right). \label{FCF}
\end{equation}
This is known as the Feynman-Kac formula.
}
\proof
{
Since $u$ has bounded and uniformly continuous derivatives up to and including second order in $x$ and first order in $t$, Lemma 2 and Theorem 1 give us that $\tilde{\Theta}u(x, t) = Lu(x, t) + V(x)u(x)$.  Since $u$ is assumed to satisfy \eqref{CP} we therefore have that $u$ satisfies \eqref{ACP}.

Since $V(x)$ is bounded, we choose an arbitrary constant $V \in \mathbb{R}$ such that $V(x) < V$ for all $x \in \mathbb{R}^n$ and define $v(x, t) = e^{-Vt}u(x, t)$.  Now,
\begin{align}
\frac{\partial v}{\partial t} & = \frac{\partial}{\partial t}(e^{-Vt}u)\nonumber\\
& = u\frac{\partial}{\partial t}(e^{-Vt}) + e^{-Vt}\frac{\partial u}{\partial t}\nonumber\\
& = -Ve^{-Vt}u + e^{-Vt}(Lu + V(x)u)\nonumber\\
& = -Ve^{-Vt}u + Le^{-Vt}u + V(x)e^{-Vt}u\nonumber\\
& = Lv + (V(x) - V)v\nonumber
\end{align}
and,
$$
v(x, 0) = e^0u(x, 0) = f(x).
$$
Hence, $v$ satisfies the initial value problem,
$$
\left\{
\begin{aligned}
\frac{\partial v}{\partial t}(x, t) & =  Lv(x, t) + (V(x) - V)v(x, t),\\ 
v(x, 0) & = f(x).
\end{aligned}
\right.
$$
Since $V(x) - V < 0$, the solution obeys the maximum principle for parabolic operators \cite{PW}, so we get,
$$
\sup_{x \in \mathbb{R}^n}|v(x, t)| \le \|f\| \Rightarrow |u(x, t)| < e^{Vt}|v(x, t)| \le e^{Vt}\|f\|
$$
i.e. $u \in K$ and as shown above $u$ solves \eqref{ACP}.  However, the solution to \eqref{ACP} is unique in $K$ and so we conclude that,
$$
u(x, t) = \tilde{T}_t^Vf(x) = \mathbb{E}\left(f(X_t^x)\exp\left(\int_0^t V(X_s^x)\,\mathrm{d}s\right)\right).
$$

\qedhere
}

This well known result will be used as a basis for the results in the next chapter.

So far we have explored the solution to the intial value (Cauchy) problem \eqref{CP}.  For the rest of the chapter we are going to modify our initial value problem and replace the initial time value with boundary constraints and explore the solution to the following boundary value (Dirichlet) problem.  Let $D \subset \mathbb{R}^n$ be a domain and have a boundary $\partial D$.  We consider the boundary value problem
\begin{equation}
\left\{
\begin{aligned}
 Lu(x) - V(x)u(x) & = f(x), \hspace{0.3cm} x \in D,\\ 
\lim_{x \to x_0}u(x) = \psi(x_0) & , \hspace{0.3cm} x_0 \in \partial D, \label{DP}
\end{aligned}
\right.
\end{equation}
where $L$ is the same operator as before with the same assumptions (Assumptions 1) on the coefficients.  The functions $f$, $V$ and $\psi$ are assumed to be continuous and bounded with $V(x) \ge 0$, for all $x \in \mathbb{R}^n$.

We introduce the first hitting time of the boundary $\partial D$ by the process $X_s^x$ given by the definition $\tau_D^x = \inf\{t : X_t^x \in \partial D\}$.  If $X_s^x$ never hits $\partial D$ then we set $\tau_D^x = \infty$.  We now give the solution to the boundary value problem \eqref{DP} in the following theorem.
\theorem
{
Suppose $\mathbb{E}(\tau_D^x) < \infty$, for all $x \in D$.  If $u$ is a bounded solution to \eqref{DP}, which has bounded, continuous first- and second-order partial derivatives in any interior subdomain $\tilde{D} \subset D$, then,
\begin{align}
u(x) & = -\mathbb{E}\left(\int_0^{\tau_D^x}f(X_t^x)\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right)\mathrm{d}t\right)\nonumber\\
& \hspace{0.5cm} + \mathbb{E}\left(\psi(X_{\tau_D^x}^x)\exp\left(-\int_0^{\tau_D^x}V(X_s^x)\,\mathrm{d}s\right)\right). \label{DPFCF}
\end{align}
}
\proof
{
We suppose that $u$ can be extended to $\mathbb{R}^n$ so that it is bounded and has bounded first- and second-order partial derivatives.  We define two processes,
$$
Y_s^x = u(X_s^x), \hspace{0.4cm} Z_s^x = \exp\left(-\int_0^sV(X_u^x)\,\mathrm{d}u\right).
$$
We want to consider their product $Y_s^xZ_s^x$, by It$\mathrm{\hat{o}}$'s product rule,
$$
\mathrm{d}(Y_s^xZ_s^x) = Z_s^x\,\mathrm{d}Y_s^x + Y_s^x\,\mathrm{d}Z_s^x + \mathrm{d}Y_s^x\,\mathrm{d}Z_s^x.
$$
We now continue by direct computation,
\begin{align}
\mathrm{d}Y_s^x & = \frac{\partial Y_s^x}{\partial s}\,\mathrm{d}s + \frac{\partial Y_s^x}{\partial x_i}\,\mathrm{d}X_s^i + \frac{1}{2}\frac{\partial^2 Y_s^x}{\partial x_i \partial x_j}\,\mathrm{d}X_s^i\,\mathrm{d}X_s^j\nonumber\\
& = \frac{\partial u}{\partial s}(X_s^x)\,\mathrm{d}s + \frac{\partial u}{\partial x_i}(X_s^x)(\sigma_{ik}\,\mathrm{d}B_t^k + b_i\,\mathrm{d}s) + \frac{1}{2}\frac{\partial^2 u}{\partial x_i \partial x_j}(X_s^x)\,a_{ij}\,\mathrm{d}s\nonumber\\
& = \frac{\partial u}{\partial x_i}(X_s^x)\,\sigma_{ik}\mathrm{d}B_t^k + \left(\frac{1}{2}a_{ij}\,\frac{\partial^2 u}{\partial x_i \partial x_j}(X_s^x) + b_i\,\frac{\partial u}{\partial x_i}(X_s^x)\right)\mathrm{d}s\nonumber\\
& = \nabla u(X_s^x)\cdot(\sigma\,\mathrm{d}B_s) + Lu(X_s^x)\,\mathrm{d}s.\nonumber
\end{align}
Next,
$$
\mathrm{d}Z_s^x = -V(X_s^x)Z_s^x\,\mathrm{d}s
$$
so,
\begin{align}
\mathrm{d}(Y_s^xZ_s^x) & = Z_s^x(\nabla u(X_s^x)\cdot(\sigma\,\mathrm{d}B_s) + Lu(X_s^x)\,\mathrm{d}s) - Z_s^xV(X_s^x)u(X_s^x)\,\mathrm{d}s\nonumber\\
& = (Lu(X_s^x) - V(X_s^x)u(X_s^x))Z_s^x\,\mathrm{d}s + (\nabla u(X_s^x)Z_s^x)\cdot(\sigma\,\mathrm{d}B_s)\nonumber\\
& = f(X_s^x)Z_s^x\,\mathrm{d}s + (Lu(X_s^x) - f(X_s^x) - V(X_s^x)u(X_s^x))Z_s^x\,\mathrm{d}s \nonumber\\
& \hspace{0.5cm} + (\nabla u(X_s^x)Z_s^x)\cdot(\sigma\,\mathrm{d}B_s).\nonumber
\end{align}
Integrating from $0$ to $t$ gives us,
\begin{align}
u(X_t^x) & Z_t^x - u(x)\nonumber\\
& = \int_0^tf(X_s^x)Z_s^x\,\mathrm{d}s + \int_0^t(Lu(X_s^x) - f(X_s^x) - V(X_s^x)u(X_s^x))Z_s^x\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \int_0^t(\nabla u(X_s^x)Z_s^x)\cdot(\sigma\,\mathrm{d}B_s)\nonumber
\end{align}
or,
\begin{align}
u(x) & = u(X_t^x)\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right)\nonumber\\
& \hspace{0.5cm} - \int_0^t(Lu(X_s^x) - f(X_s^x) - V(X_s^x)u(X_s^x))\exp\left(-\int_0^sV(X_u^x)\,\mathrm{d}u\right)\mathrm{d}s\nonumber\\
& \hspace{0.5cm} - \int_0^tf(X_s^x)\exp\left(-\int_0^sV(X_u^x)\,\mathrm{d}u\right)\mathrm{d}s - \int_0^t(\nabla u(X_s^x)Z_s^x)\cdot(\sigma\,\mathrm{d}B_s).\nonumber
\end{align}
Since the above equation holds for all $t \ge 0$, it is still valid if we replace $t$ by the random time $\tau_T = \min\{T, \tau_D^x\}$, $T \ge 0$.  Our boundary value problem \eqref{DP} does not hold if $X_s^x \notin D$ and  $X_s^x$ does not leave $D$ for $s < \tau_T$ by definition.  Hence, $Lu(X_s^x) - V(X_s^x)u(X_s^x) = f(X_s^x)$,  for $s < \tau_T$.  So we get,
\begin{align}
u(x) & = u(X_{\tau_T}^x)\exp\left(-\int_0^{\tau_T}V(X_s^x)\,\mathrm{d}s\right)\nonumber\\
& \hspace{0.5cm} - \int_0^{\tau_T}f(X_t^x)\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right)\mathrm{d}t\nonumber\\
& \hspace{0.5cm} - \int_0^{\tau_T}\left(\nabla u(X_t^x)\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right)\right)\cdot(\sigma\,\mathrm{d}B_t).\nonumber
\end{align}
Noting that $\mathbb{E}(\tau_T) \le T < \infty$, $Z_s^x$ is bounded and,
$$
\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right) \le 1
$$
we may take the expectation of the above to yield,
\begin{align}
u(x) & = \mathbb{E}\left(u(X_{\tau_T}^x)\exp\left(-\int_0^{\tau_T}V(X_s^x)\,\mathrm{d}s\right)\right)\nonumber\\
& \hspace{0.5cm} + \mathbb{E}\left(-\int_0^{\tau_T}f(X_t^x)\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right)\mathrm{d}t\right.\nonumber
\end{align}
since the expectation of a stochastic integral is zero.  Taking the limit of our expression of $u$ as $T \to \infty$, noting that $u(X_{\tau_D^x}^x) = \psi(X_{\tau_D^x}^x)$, gives us,
\begin{align}
u(x) & = \mathbb{E}\left(\psi(X_{\tau_D^x}^x)\exp\left(-\int_0^{\tau_D^x}V(X_s^x)\,\mathrm{d}s\right)\right)\nonumber\\
& \hspace{0.5cm} - \mathbb{E}\left(\int_0^{\tau_D^x}f(X_t^x)\exp\left(-\int_0^tV(X_s^x)\,\mathrm{d}s\right)\mathrm{d}t\right).\nonumber
\end{align}
This can be done as $X_s^x$ is continuous a.s., $\mathbb{E}(\tau_T) \le \mathbb{E}(\tau_D^x) < \infty$ and 
$$
\lim_{T \to \infty}\mathbb{P}\{\tau_D^x > T\} = 0, \hspace{0.3cm} \mathrm{a.s.}
$$
so we may use dominated convergence to pass the limit as $T \to \infty$.

We still have an assumption that $u$ can be extended to the whole of $\mathbb{R}^n$ for \eqref{DPFCF} to hold.  Consider a sequence of subdomains $D_n \subset D$ with smooth boundaries $\partial D_n$ that tend to $D$, the boundary value problem
$$
\left\{
\begin{aligned}
 Lu_n(x) - V(x)u_n(x) & = f(x), \hspace{0.3cm} x \in D_n,\\ 
\lim_{x \to x_0}u_n(x) = u(x_0) & , \hspace{0.3cm} x_0 \in \partial D_n,
\end{aligned}
\right.
$$
can be extended smoothly to $\mathbb{R}^n$ so it has a representation like $u$ did previously.  Since $u$ is continuous on $D \cup \partial D$ and the stopping times $\tau_n = \inf\{t : X_t^x \in \partial D_n\}$ increases monotonically to $\tau_D^x$, the validity of \eqref{DPFCF} follows from its validity for $u_n$.

\qedhere
}

The work in this chapter will be the basis for what is to follow in the coming chapters.  The Feynman-Kac formulas will be the initial representations of solutions to heat equations, we will then attempt to modify the representations to apply them to resolving the behaviour of a heat equation as the diffusivity converges to zero.








\chapter{The Stochastic Elementary Formula}

In this chapter we shall investigate the asymptotic behaviours of the solution to the heat equation as the thermal diffusivity (which we shall denote $\mu$) tends to $0$.  As we shall see, simply using a Feynman-Kac solution to the problem does not make it obvious as to how the solution behaves asymptotically, so we derive what is known as the Stochastic Elementary formula, first derived by K.D. Elworthy and A. Truman \cite{SEF4}, as a more helpful tool for investigation.  We follow A. Neate and A. Truman \cite{ANAT} for this chapter and begin by defining $u^{\mu} : \mathbb{R}^n \times [0, \infty) \to \mathbb{R}$ to be the solution to the heat equation,
\begin{equation}
\frac{\partial u^{\mu}}{\partial t}(x, t) = \frac{1}{2}\mu^2\Delta u^{\mu}(x, t) + \frac{1}{\mu^2}V(x)u^{\mu}(x, t) \label{HE}
\end{equation}
with the initial condition,
$$
u^{\mu}(x, 0) = T_{0}(x)\exp\left(-\frac{S_{0}(x)}{\mu^2}\right)
$$
where $S_{0}, T_{0}, V:\mathbb{R}^n \to \mathbb{R}$.
Before moving on we will present the typical solution using the Feynman-Kac Formula.

\assumption
{
We assume that:
\begin{enumerate}
\item $V$, $S_0$, $T_0$ are real-valued.
\item $V$ is bounded below, $S_0$ is bounded above and $T_0$ is positive and bounded.
\item The first and second order partial derivatives of $V$ and $S_0$ are uniformly bounded on $\mathbb{R}^n$.
\end{enumerate}
}

Assumption 2 alone is enough to guarantee that a unique, positive and smooth solution exists.  The Feynman-Kac Formula gives,
$$
u^{\mu}(x, t) = \mathbb{E}\left(T_{0}(B^{\mu}_t)\exp\left(-\frac{1}{\mu^2}S_{0}(B^{\mu}_t) + \frac{1}{\mu^2}\int_{0}^{t}V(B^{\mu}_s)\,\mathrm{d}s\right)\right)
$$
where $B^{\mu}_t = x + \mu B_{t}$ and $B_{t}$ is an $n$-dimensional Brownian Motion on a probability space $(\Omega, \mathscr{F}, \mathbb{P})$.  Also, $\mathbb{E}$ is the expectation with respect to the probability measure $\mathbb{P}$.  It is obvious that we run into problems trying to take the limit as $\mu \to 0$ due to the $\frac{1}{\mu^2}$ term in the integrand, hence the motivation for a different representation.

To move forward, we introduce the mapping $\Phi_t :\mathbb{R}^n \to \mathbb{R}^n$, defined by the differential equation,
\begin{equation}
\left\{
\begin{aligned}
\ddot{\Phi}_t(x) & = -\nabla V(\Phi_t(x)), \hspace{0.3cm} t \in [0, \tilde{T}), \hspace{0.3cm} \tilde{T} > 0,\\ \label{CMFMD}
\dot{\Phi}_0(x) & = \nabla S_0(x), \\
\Phi_0(x) & = x.
\end{aligned}
\right.
\end{equation}
where $\tilde{T}$ is a fixed, positive and finite terminal time.  From a mechanics perspective, $\Phi_t$ is the classical mechanical flow map of a particle of unit mass under the influence of a potential $V$ (it is easy to see that this is Newton's second law of motion).  Assuming $\Phi_t$ is uniquely determined for all $t$ up to the termination time $\tilde{T}$, we introduce some definitions to define the most crucial property of this flow map for what is to follow.
\definition
{
A differentiable and bijective mapping $f :\mathbb{R}^m \to \mathbb{R}^n$ is called a \emph{diffeomorphism} if its inverse $f^{-1}:\mathbb{R}^n \to \mathbb{R}^m$ is differentiable also.
}
\definition
{
We say that $\Phi_t$ (as in \eqref{CMFMD}) satisfies the \emph{no-caustic condition} if there exists a \emph{caustic time} $T \in (0, \tilde{T}]$ such that $\Phi_t :\mathbb{R}^n \to \mathbb{R}^n$ is a diffeomorphism for all $t \in [0, T)$.
}

The no-caustic condition is essential for what is to follow, so in order to guarantee the existence of a positive caustic time $T$ we need the following theorem that we give without proof.
\theorem
{
Let $F :\mathbb{R}^n \to \mathbb{R}^n$ be a smooth map such that there exists $C > 0$ with $|DF(x)y| \ge C|y|$, for all $x, y \in \mathbb{R}^n$, where $DF(x)$ denotes the Fr$\acute{e}$chet derivative of $F(x)$.  If $F$ is homotopic to a homeomorphism then $F$ is a diffeomorphism.
}
\proof
{
See \cite{SEF2}.

\qedhere
}

The next theorem guarantees the existence of our caustic time.  In order to solve it however, we need a quick lemma.
\lemma
{
Let $\xi :\mathbb{R} \to \mathbb{R}$ be the solution to
$$
\left\{
\begin{aligned}
\ddot{\xi}(x) & - \beta^2\xi(x) = 1 + \alpha x\\
\xi(0) & = \dot{\xi}(0) = 0
\end{aligned}
\right.
$$
then, $\xi$ is given explicitly by,
$$
\xi(x) = \frac{1}{\beta^3}(\alpha\sinh(\beta x) + \beta(\cosh(\beta x) - \alpha x - 1)).
$$
}
\proof
{
Define $\xi := \xi_c + \xi_p$, where $\xi_c$ is the general solution to $\ddot{\xi_c}(x) - \beta^2\xi_c(x) = 0$ and $\xi_p$ is a particular solution to $\ddot{\xi_p}(x) - \beta^2\xi_p(x) = 1 + \alpha x$.  To solve $\xi_c$ we use the method of characteristic polynomials.  The roots of the characteristic equation are $\pm\beta$ and so the solution is of the form $\xi_c(x) = Ae^{\beta x} + Be^{-\beta x}$, where $A, B$ are constants.  Next, we suppose $\xi_p = C + Dx$ and by substituting in to $\ddot{\xi_p}(x) - \beta^2\xi_p(x) = 1 + \alpha x$ and comparing co-efficients yields $C = -\frac{1}{\beta^2}$ and $D = -\frac{\alpha}{\beta^2}$.  Going back to the definition of $\xi$ we arrive at the general solution of,
$$
\xi(x) = Ae^{\beta x} + Be^{-\beta x} - \frac{\alpha}{\beta^2}x - \frac{1}{\beta^2}.
$$

Using the initial conditions we arrive at 2 simultaneous equations for $A$ and $B$
$$
\left\{
\begin{aligned}
A + B & = \frac{1}{\beta^2}\\
A - B & = \frac{\alpha}{\beta^3}
\end{aligned}
\right.
$$
giving $A = \frac{\beta + \alpha}{2\beta^3}$ and $B = \frac{\beta - \alpha}{2\beta^3}$.  Substituting in and rearranging gives the final result,
$$
\xi(x) = \frac{1}{\beta^3}(\alpha\sinh(\beta x) + \beta(\cosh(\beta x) - \alpha x - 1)).
$$

\qedhere
}

Now on to the theorem.
\theorem
{
Let $D^2S_0$ denote the Hessian of $S_0$ (as defined earlier) and $\sigma$ denote the spectrum.  We define,
\begin{align}
\mu_{\mathrm{max}}(x_0) & = \sup\{\alpha : \alpha \in \sigma (D^2S_0(x_0)) \}\nonumber\\
\mu_{\mathrm{min}}(x_0) & = \inf\{\beta : \beta \in \sigma (D^2S_0(x_0)) \}\nonumber
\end{align}
and
$$
\mu_{\mathrm{max}} = \sup_{x_0}\mu_{\mathrm{max}}(x_0),
\hspace{3mm}
\mu_{\mathrm{min}} = \sup_{x_0}\mu_{\mathrm{min}}(x_0),
\hspace{3mm}
\lambda^2 = \sup_{\substack{s \in [0, \tilde{T})\\x_0 \in \mathbb{R}^n}}\|D^2V(\Phi_s(x_0))\|
$$
where $\|\cdot\|$ denotes the spectral norm (i.e. the largest eigenvalue of the matrix).  Then, under Assumption 2, $\Phi_t$ satisfies the no-caustic condition with the caustic time $T > 0$ given by the least positive solution to,
$$
(1 + T\mu_{\mathrm{min}})\left(2 + T(\mu_{\mathrm{min}} + \mu_{\mathrm{max}}) - \frac{1}{\lambda}\mu_{\mathrm{max}}\sinh(T\lambda) - \cosh(T\lambda)\right) = 0.
$$
}
\proof
{
From the definition of $\Phi_t$ \eqref{CMFMD} and for a fixed $x_0 \in \mathbb{R}^n$,
$$
\ddot{\Phi}_s(x_0) = -\nabla V(\Phi_s(x_0)), \hspace{0.3cm} s \in [0, \tilde{T})
$$
integrating this and using the initial condition $\dot{\Phi}_0(x_0) = \nabla S_0(x_0)$ gives,
$$
\dot{\Phi}_s(x_0) = \nabla S_0(x_0) - \int_0^s\nabla V(\Phi_u(x_0))\,\mathrm{d}u
$$
then integrating again and using the second initial condition $\Phi_0(x_0) = x_0$ gives,
$$
\Phi_s(x_0) = x_0 + s\nabla S_0(x_0) - \int_0^s\int_0^u \nabla V(\Phi_v(x_0))\,\mathrm{d}v\,\mathrm{d}u.
$$
We now denote $J(s) = D\Phi_s(x_0)$, thus,
\begin{align}
J(s) & = D\Phi_s(x_0)\nonumber\\
& = Dx_0 + sD(\nabla S_0(x_0)) - \int_0^s\int_0^u D(\nabla V(\Phi_v(x_0)))\,\mathrm{d}v\,\mathrm{d}u\nonumber\\
& = I + sD^2S_0(x_0) - \int_0^s\int_0^u D^2V(\Phi_v(x_0))D\Phi_v(x_0)\,\mathrm{d}v\,\mathrm{d}u.\nonumber
\end{align}
Hence,
\begin{equation}
J(s) = I + sD^2S_0(x_0) - \int_0^s\int_0^u D^2V(\Phi_v(x_0))J(v)\,\mathrm{d}v\,\mathrm{d}u. \label{Frechet}
\end{equation}
Next we define,
$$
f(s) = \int_0^s\int_0^u \|J(v)\|\,\mathrm{d}v\,\mathrm{d}u
$$
then,
\begin{align}
& \left\|\int_0^s\int_0^u D^2V(\Phi_v(x_0))J(v)\,\mathrm{d}v\,\mathrm{d}u\right\|\nonumber\\
& \hspace{1.5cm} \le \int_0^s\int_0^u \|D^2V(\Phi_v(x_0))J(v)\|\,\mathrm{d}v\,\mathrm{d}u\nonumber\\
& \hspace{1.5cm} \le \int_0^s\int_0^u \|D^2V(\Phi_v(x_0))\|\|J(v)\|\,\mathrm{d}v\,\mathrm{d}u\nonumber\\
& \hspace{1.5cm} \le \int_0^s\int_0^u \left(\sup_{v \in [0, \tilde{T})}\|D^2V(\Phi_v(x_0))\|\right)\|J(v)\|\,\mathrm{d}v\,\mathrm{d}u\nonumber\\
& \hspace{1.5cm} = \left(\sup_{v \in [0, \tilde{T})}\|D^2V(\Phi_v(x_0))\|\right) \int_0^s\int_0^u \|J(v)\|\,\mathrm{d}v\,\mathrm{d}u\nonumber\\
& \hspace{1.5cm} = \lambda^2 f(s)\nonumber
\end{align}
by the triangle inequality for integrals and the submultiplicativity of the spectral norm.  Next, if we suppose $1 + \mu_{\mathrm{min}}(x_0) > 0$ then $ I + sD^2S_0(x_0)$ has positive eigenvalues and is therefore positive definite.  We then take the spectral norm of \eqref{Frechet} to yield,
\begin{align}
\|J(s)\| & = \left\|I + sD^2S_0(x_0) - \int_0^s\int_0^u D^2V(\Phi_v(x_0))J(v)\,\mathrm{d}v\,\mathrm{d}u\right\|\nonumber\\
& \le \|I + sD^2S_0(x_0)\| + \left\|\int_0^s\int_0^u D^2V(\Phi_v(x_0))J(v)\,\mathrm{d}v\,\mathrm{d}u\right\| \nonumber\\
& \le 1 + s\mu_{\mathrm{max}}(x_0) + \lambda^2f(s)\nonumber
\end{align}
i.e. $\ddot{f}(s) \le 1 + s\mu_{\mathrm{max}}(x_0) + \lambda^2f(s)$, with $f(0) = \dot{f}(0) = 0$ by definition of $f$.  We define $g$ as the solution to,
$$
\left\{
\begin{aligned}
\ddot{g}(s) & = 1 + s\mu_{\mathrm{max}}(x_0) + \lambda^2g(s),\\
g(0) & = \dot{g}(0) = 0.
\end{aligned}
\right.
$$
Clearly, $f \le g$ and by Lemma 4 we arrive at,
$$
f(s) \le g(s) = \frac{1}{\lambda^3}(\mu_{\mathrm{max}}(x_0)\sinh(\lambda s) + \lambda(\cosh(\lambda s) - \mu_{\mathrm{max}}(x_0) - 1)).
$$

Next we use a property of matrices.  If $A$ is an invertible matrix and $B$ is a matrix such that $\|B\| < \|A^{-1}\|^{-1}$ then we have the inequality $\|(A + B)^{-1}\| < (\|A^{-1}\|^{-1} - \|B\|)^{-1}$.
It follows, for all $s \in [0, T)$, that $J(s)$ is invertible and
\begin{align}
\lefteqn{\|J^{-1}(s)\|}\nonumber\\
& = \left\|\left((I + sD^2S_0(x_0)) + \left(-\int_0^s\int_0^u D^2V(\Phi_v(x_0))J(v)\,\mathrm{d}v\,\mathrm{d}u\right)\right)^{-1}\right\|\nonumber\\
& < \left(\|(I + sD^2S_0(x_0))^{-1}\|^{-1} - \left\|\int_0^s\int_0^u D^2V(\Phi_v(x_0))J(v)\,\mathrm{d}v\,\mathrm{d}u\right\|\right)^{-1}\nonumber\\
& < (1 + s\mu_{\mathrm{min}}(x_0) - \lambda^2g(s))^{-1}\nonumber
\end{align}
provided, $\lambda^2g(s) < 1 + s\mu_{\mathrm{min}}(x_0)$ and $0 < 1 + s\mu_{\mathrm{min}}(x_0)$.  Hence, by submultiplicativity with respect to the Euclidean norm, for all $y \in \mathbb{R}^n$,
$$
\|J^{-1}(s)y\|^* \le \|J^{-1}(s)\|\|y\|^* \le C^{-1}\|y\|^*
$$
where, $\|\cdot\|^*$ denotes the Euclidean norm on $\mathbb{R}^n$ and 
$$
C^{-1} = \sup_{x_0}(1 + s\mu_{\mathrm{min}}(x_0) - \lambda^2g(s))^{-1} < \infty.
$$
So, setting $y = J(s)x$ gives $\|(D\Phi_s(x_0))x\|^* = \|J(s)x\|^* \ge C\|x\|^*$ the required inequality for Theorem 4, all that remains is to show that $\Phi_t$ is homotopic to a homeomorphism.  This is trivial as $\Phi_t$ is continuous in $t$ and by definition, $\Phi_0 = id$, the identity, which is clearly a homeomorphism.  So the result follows that $\Phi_t$ satisfies the no-caustic condition for the caustic time $T$.

\qedhere
}

We will now use some well-known ideas from classical mechanics regarding the connection between the classical mechanical flow map and the Hamilton-Jacobi equation \cite{Arnol'd}.  To begin with we will suppose that $\Phi_t$ describes the path of a particle of unit mass as defined in \eqref{CMFMD}, then we define its action functional as
\begin{align}
\mathscr{A}_t(x_0) & = S_0(x_0) + \int_0^t \mathscr{L}(\Phi_s(x_0), \dot{\Phi}_s(x_0)) \,\mathrm{d}s\nonumber\\
& = S_0(x_0) + \frac{1}{2}\int_0^t \|\dot{\Phi}_s(x_0)\|^2 \,\mathrm{d}s - \int_0^t V(\Phi_s(x_0)) \,\mathrm{d}s\nonumber
\end{align}
where $\mathscr{L}$ is the system's Lagrangian and $x_0$ is our initial position.

We can now define Hamilton's principal function for all $t \in [0, T)$ as,
$$
S(x, t) = \mathscr{A}_t(\Phi_t^{-1}(x)).
$$
Note that since we have set $x_0 = \Phi_t^{-1}(x)$, it follows that $S$ evaluates the action along the path $(x_0, 0) \to (x, t)$ under $\Phi_t$.  Now by standard results in classical mechanics, $S(x, t)$ satisfies the Hamilton-Jacobi equation,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial S}{\partial t}(x, t) + \frac{1}{2}\|\nabla S(x, t)\|^2 + V(x) = 0,\\ \label{HJE}
& S(x, 0) = S_0(x).
\end{aligned}
\right.
\end{equation}

This equation will be of importance in the next theorem as we combine the Hamilton-Jacobi equation with the Feynman-Kac formula to derive the stochastic elementary formula.
\theorem
{
If, for a caustic time $T > 0$, $u^{\mu}(x, t)$ satisfies the no-caustic condition, then for all $t \in [0, T)$ we have,
\begin{equation}
u^\mu(x, t) = \mathrm{exp}\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right)\right) \label{SEF}
\end{equation}
where $X^{\mu}_{s}$ satisfies the S.D.E.,
\begin{equation}
\left\{
\begin{aligned}
\mathrm{d}X^{\mu}_{s} & = -\nabla S(X^{\mu}_{s}, t - s)\,\mathrm{d}s + \mu\,\mathrm{d}B_{s}, \hspace{0.3cm} s \in [0, t], \\ \label{Diffusion}
\hspace{0.2cm}X^{\mu}_{0} & = x.
\end{aligned}
\right.
\end{equation}
}
\proof
{
Since $S(x, t)$ is suitably differentiable we can apply It$\mathrm{\hat{o}}$'s formula for multi-dimensional processes to $Y^{\mu}_{s} := S(X^{\mu}_{s}, t - s)$ to yield,
\begin{align}
\mathrm{d}Y^{\mu}_{s} & = \frac{\partial S}{\partial s}(X^{\mu}_{s}, t - s)\,\mathrm{d}s + \sum_{i = 1}^n \frac{\partial S}{\partial x_{i}}(X^{\mu}_{s}, t - s)\,\mathrm{d}X^{i}_{s}\nonumber\\
& \hspace{0.5cm} + \frac{1}{2}\sum_{i, j = 1}^{n} \frac{\partial^2 S}{\partial x_{i} \partial x_{j}}(X^{\mu}_{s}, t - s)\,\mathrm{d}X^{i}_{s}\,\mathrm{d}X_s^j\nonumber\\
& = \frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s)\frac{\partial(t - s)}{\partial s}\,\mathrm{d}s + \sum_{i = 1}^n \frac{\partial S}{\partial x_{i}}(X^{\mu}_{s}, t - s)\,\mathrm{d}X^{i}_{s}\nonumber\\
& \hspace{0.5cm} + \frac{1}{2}\sum_{i, j = 1}^{n} \frac{\partial^2 S}{\partial x_{i} \partial x_{j}}(X^{\mu}_{s}, t - s)\,\mathrm{d}X^{i}_{s}\,\mathrm{d}X_s^j\nonumber\\
& = -\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s)\,\mathrm{d}s + \sum_{i = 1}^n \frac{\partial S}{\partial x_{i}}(X^{\mu}_{s}, t - s)\,\mathrm{d}X^{i}_{s}\nonumber\\
& \hspace{0.5cm} + \frac{1}{2}\sum_{i, j = 1}^{n} \frac{\partial^2 S}{\partial x_{i} \partial x_{j}}(X^{\mu}_{s}, t - s)\,\mathrm{d}X^{i}_{s}\,\mathrm{d}X_s^j\nonumber
\end{align}
where $\mathrm{d}X^{i}_{s} = -\frac{\partial S}{\partial x_{i}}\,\mathrm{d}s + \mu\,\mathrm{d}B_s^i$, i.e. the $\mathrm{i^{th}}$ component of $\mathrm{d}X^{\mu}_{s}$ and $\mathrm{d}B_s^i$ is the $\mathrm{i^{th}}$ component of $\mathrm{d}B_{s}$.  Note that where appropriate we use the notation $\frac{\partial}{\partial t}$ to denote $\left.\frac{\partial}{\partial t}\right|_{t = t - s}$ for convenience, this convention will be used in similar proofs throughout.
\\Now, 
\begin{align}
\mathrm{d}X^{i}_{s}\,\mathrm{d}X_s^j & = \left(-\frac{\partial S}{\partial x_{i}}\,\mathrm{d}s + \mu\,\mathrm{d}B_s^i\right)\left(-\frac{\partial S}{\partial x_{j}}\mathrm{d}s + \mu\mathrm{d}B_s^j\right), \hspace{0.3cm} \text{for } i \ne j \nonumber \\
& = 0 \nonumber
\end{align}
and,
\begin{align}
\mathrm{d}X^{i}_{s}\,\mathrm{d}X^{i}_{s} & = \left(-\frac{\partial S}{\partial x_{i}}\mathrm{d}s + \mu\mathrm{d}B_s^i\right)\left(-\frac{\partial S}{\partial x_{i}}\mathrm{d}s + \mu\mathrm{d}B_s^i\right) \nonumber \\
& = \mu^2(\mathrm{d}B_s^i)^2 \nonumber \\
& = \mu^2\mathrm{d}s \nonumber
\end{align}
using the identites, $(\mathrm{d}s)^2 = \mathrm{d}s\,\mathrm{d}B_s^i = \mathrm{d}B_s^i\,\mathrm{d}s = \mathrm{d}B_s^i\,\mathrm{d}B_s^j = 0$, $i \ne j$ and $(\mathrm{d}B_s^i)^2 = \mathrm{d}s$.  We now have,
\begin{align}
\mathrm{d}Y^{\mu}_{s} & = -\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s)\,\mathrm{d}s + \sum_{i = 1}^n \frac{\partial S}{\partial x_{i}}(X^{\mu}_{s}, t - s)\left(-\frac{\partial S}{\partial x_{i}}\,\mathrm{d}s + \mu\,\mathrm{d}B_s^i\right)\nonumber\\
& \hspace{0.5cm} + \frac{1}{2}\sum_{i, j = 1}^{n} \frac{\partial^2 S}{\partial x_{i} \partial x_{j}}(X^{\mu}_{s}, t - s)(\mu^2\mathrm{d}s)\nonumber\\
& = \left(-\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s) - \sum_{i = 1}^n \left(\frac{\partial S}{\partial x_{i}}\right)^2(X^{\mu}_{s}, t - s)\right.\nonumber\\
& \hspace{0.5cm} + \left.\frac{\mu^2}{2}\sum_{i = 1}^{n} \frac{\partial^2 S}{\partial x_{i}^2}(X^{\mu}_{s}, t - s)\right)\mathrm{d}s + \mu\sum_{i = 1}^n \frac{\partial S}{\partial x_{i}}(X^{\mu}_{s}, t - s)\,\mathrm{d}B_s^i.\nonumber
\end{align}
Using vector calculus notation gives,
\begin{align}
\mathrm{d}S & (X^{\mu}_{t}, t - s)\nonumber\\
& = \left(-\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s) - \|\nabla S(X^{\mu}_{s}, t - s)\|^2 + \frac{\mu^2}{2}\Delta S(X^{\mu}_{s}, t - s)\right)\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \mu\nabla S(X^{\mu}_{s}, t - s)\cdot\mathrm{d}B_{s}.\nonumber
\end{align}
Finally, re-arranging and integrating from $0$ to $t$ yields,
\begin{align}
\mu\int _0^t\nabla S&(X^{\mu}_{s}, t - s)\cdot\mathrm{d}B_{s} = S_{0}(X^{\mu}_{t}) - S(x, t)\nonumber\\
& + \int _0^t\left(\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s) + \|\nabla S(X^{\mu}_{s}, t - s)\|^2 - \frac{\mu^2}{2}\Delta S(X^{\mu}_{s}, t - s)\right)\mathrm{d}s\nonumber
\end{align}
We will now apply the Girsanov-Cameron-Martin Theorem (see for instance \cite{Oksendal}) to our solution to $u^\mu(x, t)$ in its Feynman-Kac representation.  We define,
$$
M_t = \exp\left(-\frac{1}{2\mu^2}\int _0^t \|\nabla S(X^{\mu}_{s}, t - s)\|^2 \mathrm{d}s + \frac{1}{\mu}\int _0^t \nabla S(X^{\mu}_{s}, t - s)\cdot \mathrm{d}B_s\right)
$$
to be the Radon-Nikodym derivative of the change of measure.  Using our derived expression for $\int _0^t\nabla S(X^{\mu}_{s}, t - s)\cdot\mathrm{d}B_{s}$ and applying the change of measure gives us,
\begin{align}
& \hspace{0.5cm} u^\mu(x, t)\nonumber\\
& = \mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{\mu^2}S_{0}(X^{\mu}_{s}) + \frac{1}{\mu^2}\int_0^t V(X^{\mu}_{s})\,\mathrm{d}s\right.\right. \nonumber\\
& \hspace{0.5cm} - \frac{1}{2\mu^2}\int _0^t \|\nabla S(X^{\mu}_{s}, t - s)\|^2\,\mathrm{d}s + \frac{1}{\mu^2}(S_{0}(X^{\mu}_{t}) - S(x, t))\nonumber\\
& \hspace{0.5cm} + \frac{1}{\mu^2}\int _0^t\left(\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s) + \|\nabla S(X^{\mu}_{s}, t - s)\|^2\right.\nonumber\\
& \hspace{2.5cm} - \left.\left.\left.\frac{\mu^2}{2}\Delta S(X^{\mu}_{s}, t - s)\right)\mathrm{d}s\right)\right)\nonumber\\
& = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left( - \frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right.\right.\nonumber \\
& \hspace{0.5cm} + \frac{1}{\mu^2}\left.\left.\int _0^t\left(\frac{\partial S}{\partial t}(X^{\mu}_{s}, t - s) + \frac{1}{2}\|\nabla S(X^{\mu}_{s}, t - s)\|^2 + V(X^{\mu}_{s})\right)\mathrm{d}s\right)\right).\nonumber
\end{align}
Finally, the result follows from the Hamilton-Jacobi equation \eqref{HJE}.

\qedhere
}

This equation provides a tool for investigating the asymptotic behaviour of $u^\mu(x, t)$.  To progress we need a lemma involving matrix differential equations, so first we define a family of matrix value functions,
$$
\mathcal{M}_T = \left\{ A: [0, T) \to \mathbb{R}^{n \times n} : A(t) \text{ continuous}, \|A\|_\infty := \sup_{s \in [0, T)} \|A(s)\| < \infty \right\}
$$
and the time-ordered exponential $\exp_+ : \mathcal{M}_T \to \mathcal{M}_T$ given explicitly by
$$
\exp_+ A(t) = I + \int_0^t A(t_1)\,\mathrm{d} t_1 + \int_0^t A(t_1)\,\mathrm{d} t_1 \int_0^{t_1} A(t_2)\,\mathrm{d} t_2 + \dots
$$
where $0 \le t_1 < t_2 < \dots < t < T$.  Note that the products of integrals are arranged in order of strictly increasing times $t_j$, $j\in \mathbb{N}$ and the infinite series converges uniformly $\forall t \in [0, T)$ in $\mathcal{M}_T$.
\lemma
{
Let $A \in \mathcal{M}_T$, then $\exp_+A(t)$ solves the matrix differential equation,
$$
\left\{
\begin{aligned}
& \frac{\mathrm{d}}{\mathrm{d}t}\exp_+A(t) = A(t)\exp_+A(t),\\
& \exp_+A(0) = I,
\end{aligned}
\right.
$$
and
$$
\det(\exp_+A(t)) = \exp \left( \int_0^t \mathrm{tr}\,A(s)\,\mathrm{d}s \right).
$$
}
\proof
{
We prove the first part by direct computation using the definition of $\exp_+$,
\begin{align}
\frac{\mathrm{d}}{\mathrm{d} t}\exp_+ A(t) & = \frac{\mathrm{d}}{\mathrm{d} t}\left(I + \int_0^t A(t_1)\,\mathrm{d} t_1 + \int_0^t A(t_1)\,\mathrm{d} t_1 \int_0^{t_1} A(t_2)\,\mathrm{d} t_2 + \dots\right)\nonumber\\
& = A(t) + A(t)\int_0^{t_1}A(t_2)\,\mathrm{d} t_2 + \dots\nonumber\\
& = A(t)\left(I + \int_0^{t_1} A(t_2)\,\mathrm{d} t_2 + \dots \right)\nonumber\\
& = A(t)\exp_+A(t)\nonumber
\end{align}
and again, by definition $\exp_+A(0) = I$.  To prove the second part, we expand using a Taylor series centred at $t$,
\begin{align}
\exp_+A(t + h) & = \exp_+A(t) \nonumber\\
& \hspace{0.5cm} + (\exp_+A)'(t)(t + h - t) + \sum_{i = 2}^\infty \frac{(\exp_+A)^{(i)}(t)}{i!}(t + h - t)^i \nonumber\\
& = \exp_+A(t) + hA(t)\exp_+A(t) + o(h). \nonumber
\end{align}
Taking the determinant of each side gives,
\begin{align}
\det\exp_+A(t + h) & = \det(I + hA(t))\det\exp_+A(t) + o(h)\nonumber\\
& = (1 + h\,\mathrm{tr}A(t) + o(h^2))\det\exp_+A(t) + o(h)\nonumber\\
& = \det\exp_+A(t) + h\,\mathrm{tr}A(t)\det\exp_+A(t) + o(h)\nonumber
\end{align}
or equivalently,
$$
\frac{\det\exp_+A(t + h) - \det\exp_+A(t)}{h} = \mathrm{tr}A(t)\det\exp_+A(t) + \frac{o(h)}{h}.
$$
Now, by using the derivative definition,
\begin{align}
\frac{\mathrm{d}}{\mathrm{d}t}\det\exp_+A(t) & = \lim_{h \to 0} \frac{\det\exp_+A(t + h) - \det\exp_+A(t)}{h}\nonumber\\
& = \lim_{h \to 0}\left(\mathrm{tr}A(t)\det\exp_+A(t) + \frac{o(h)}{h}\right)\nonumber\\
& = \mathrm{tr}A(t)\det\exp_+A(t).\nonumber
\end{align}
From this the result clearly follows.

\qedhere
}

Before moving on we recall the definition of $X_s^\mu$ given by \eqref{Diffusion} to define the initial value problem,
$$
\left\{
\begin{aligned}
\dot{X_s^0} & = -\nabla S(X_s^0, t - s), 0 \le s \le t < T,\\
\hspace{0.2cm}X_0^0 & = x.
\end{aligned}
\right.
$$
where $T$ is our caustic time.  It can also be shown (in a similar fashion to Theorem 12, part 1 of Chapter 3) that $\Phi_t$ satisfies,
$$
\dot{\Phi}_t(x) = \nabla S(\Phi_t(x), t)
$$
or,
$$
\dot{\Phi}_{t - s}(x) = \nabla S(\Phi_{t - s}(x), t - s) \Leftrightarrow \frac{\mathrm{d}}{\mathrm{d} s}\Phi_{t - s}(x) = -\nabla S(\Phi_{t - s}(x), t - s)
$$
We would like $\Phi_{t - s}(x) = x$ when $s = 0$ so that $\Phi_{t - s}$ has the same initial value as $X_s^0$, hence, we replace $x$ by $\Phi_t^{-1}(x)$ then we have the initial value problem,
$$
\left\{
\begin{aligned}
\dot{F_s}(x) & = -\nabla S(F_s(x), t - s), 0 \le s \le t < T,\\
\hspace{0.2cm}F_0(x) & = x,
\end{aligned}
\right.
$$
where, $F_s(x) = \Phi_{t - s}(\Phi_t^{-1}(x))$.  Clearly, $F_s$ and $X_s^0$ satisfy the same intital value problem and therefore,
$$
X_s^0(x) = \Phi_{t - s}(\Phi_t^{-1}(x)).
$$
Thus, $X_s^0$ is the time reversed classical mechanical path which reaches $x$ at time $t$.  This identity is used extensively throughout the rest of this chapter.
\theorem
{
Given that the no-caustic condition holds for the caustic time $T > 0$, then
$$
\exp\left(\int_0^t \mathrm{tr}\,S''(s)\,\mathrm{d}s\right) = \det D\Phi_t(y)|_{y = \Phi_t^{-1}(x)}, \hspace{0.4cm}\forall t \in [0, T)
$$
where $S''$ is the Van Vleck matrix defined as,
$$
S''(s) = D^2S(y, s)|_{y = \Phi_s(\Phi_t^{-1}(x))}.
$$
}
\proof
{
The elements of $S''$ are given by,
\begin{align}
\left.\frac{\partial^2 S}{\partial y_i \partial y_j}(y, s)\right|_{y = \Phi_s(\Phi_t^{-1}(x))} & = \left.\frac{\partial}{\partial y_i}\left(\frac{\partial}{\partial y_j}\mathscr{A}_s(\Phi_s^{-1}(y))\right)\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& = \left.\frac{\partial}{\partial y_i}\left(\dot{\Phi}_s(\Phi_s^{-1}(y))\right)_j\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& = \left.\frac{\partial \dot{\Phi}_s}{\partial y_i}(\Phi_s^{-1}(y))\frac{\partial}{\partial y_i}(\Phi_s^{-1}(y))\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& = \left.\frac{\mathrm{d}}{\mathrm{d}t}\left(\frac{\partial \Phi_s}{\partial y_i}(\Phi_s^{-1}(y))\right)\frac{\partial}{\partial y_i}(\Phi_s^{-1}(y))\right|_{y = \Phi_s(\Phi_t^{-1}(x))}.\nonumber
\end{align}
We will need a small result derived here for the inverse of the Fr$\acute{\text{e}}$chet derivative, we have by definition of inverse mappings,
$$
D\Phi_s(\Phi_s^{-1}(y)) = Dy = I
$$
also, by the chain rule,
$$
D\Phi_s(\Phi_s^{-1}(y)) = ((D\Phi_s)(\Phi_s^{-1}(y)))D\Phi_s^{-1}(y).
$$
In other words,
$$
D\Phi_s^{-1}(y) = ((D\Phi_s)(\Phi_s^{-1}(y)))^{-1}.
$$
Using this result and the form of elements of $S''$ represented in matrix notation yields,
\begin{align}
S''(s) & = \left.\left(\frac{\mathrm{d}}{\mathrm{d}s}((D\Phi_s)(\Phi_s^{-1}(y)))\right)D\Phi_s^{-1}(y)\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& = \left.\left(\frac{\mathrm{d}}{\mathrm{d}s}((D\Phi_s)(\Phi_s^{-1}(y)))\right)((D\Phi_s)(\Phi_s^{-1}(y)))^{-1}\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& = \left(\frac{\mathrm{d}}{\mathrm{d}s}(D\Phi_s(\Phi_t^{-1}(x)))\right)(D\Phi_s(\Phi_t^{-1}(x)))^{-1}\nonumber\\
& = \frac{\mathrm{d}}{\mathrm{d}s}J(s)\,J^{-1}(s).\nonumber
\end{align}
Or in a more familiar form $S''(s)J(s) = \frac{\mathrm{d}}{\mathrm{d}s}J(s)$.  So from Lemma 5 we conclude that $J(s) = \exp_+S''(s)$ and the latter part gives us the identity,
\begin{align}
\exp\left(\int_0^t \mathrm{tr}\,S''(s)\,\mathrm{d}s\right) & = \det\exp_+ S''(t)\nonumber\\
& = \det J(t)\nonumber\\
& = \left.\det D\Phi_t(y)\right|_{y = \Phi_t^{-1}(x)}.\nonumber
\end{align}

\qedhere
}

Some corollaries follow from these theorems, the first being the asymptotic behaviour we have strived to achieve in this chapter.
\corollary
{
Given that $\Delta S(x, t)$ is bounded below for all $t \in [0, T)$, where $T$ is our caustic time for which the no-caustic condition holds.  Then
$$
\lim_{\mu \to 0} \exp\left(\frac{S(x, t)}{\mu^2}\right)u^\mu(x, t) = T_0(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}.
$$
}
\proof
{
First, using the change of variables $u = t - s$,
\begin{align}
\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^0_{s}, t - s)\,\mathrm{d}s\right) & = \exp\left(-\frac{1}{2}\int_0^t \Delta S(\Phi_{t - s}(\Phi_t^{-1}(x)), t - s)\,\mathrm{d}s\right)\nonumber\\
& = \exp\left(-\frac{1}{2}\int_t^0 \Delta S(\Phi_u(\Phi_t^{-1}(x)), u) (-\mathrm{d}u)\right)\nonumber\\
& = \exp\left(-\frac{1}{2}\int_0^t \sum_{i = 1}^n\frac{\partial^2 S}{\partial x_i^2}(\Phi_s(\Phi_t^{-1}(x)), s)\,\mathrm{d}s\right)\nonumber\\
& = \exp \left(-\frac{1}{2}\int_0^t \mathrm{tr}\,S''(s)\,\mathrm{d}s\right)\nonumber\\
& = \left(\exp \left(\int_0^t \mathrm{tr}\,S''(s)\,\mathrm{d}s\right)\right)^{-\frac{1}{2}}\nonumber\\
& = \sqrt{|\det \left[D\Phi_t(y)\right]_{y = \Phi_t^{-1}(x)}|^{-1}}\nonumber\\
& = \sqrt{|\det D\Phi_t^{-1}(x)|}.\nonumber
\end{align}
Next, we take a limit of the stochastic elementary formula representation of $u^\mu(x, t)$,
\begin{align}
\lim_{\mu \to 0} & \exp\left(\frac{S(x, t)}{\mu^2}\right)u^\mu(x, t)\nonumber\\
& = \lim_{\mu \to 0}\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right)\right)\nonumber
\end{align}
then by dominated convergence,
\begin{align}
\lim_{\mu \to 0} & \exp\left(\frac{S(x, t)}{\mu^2}\right)u^\mu(x, t)\nonumber\\
& = \mathbb{E}\left(T_{0}(\Phi_t^{-1}(x))\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^0_{s}, t - s)\,\mathrm{d}s\right)\right)\nonumber\\
& = \mathbb{E}\left(T_{0}(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}\right)\nonumber\\
& = T_{0}(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}.\nonumber
\end{align}

\qedhere
}

For our second corollary we need some preparatory work.  As an intermediate step we define a new function,
$$
S^\mu(x, t) = -\mu^2\ln u^\mu(x, t).
$$
Restricting ourselves to one spatial dimension for ease of calculation, we have:
\begin{align}
\frac{\partial S^\mu}{\partial t}(x, t) & + \frac{1}{2}\left(\frac{\partial S^\mu}{\partial x}(x, t)\right)^2 + V(x)\nonumber\\
& = -\mu^2\frac{\partial}{\partial t}(\ln u^\mu) + \frac{1}{2}\left(-\mu^2\frac{\partial}{\partial x}(\ln u^\mu)\right)^2 + V(x)\nonumber\\
& = -\mu^2\frac{\partial}{\partial u^\mu}(\ln u^\mu)\frac{\partial u^\mu}{\partial t} + \frac{1}{2}\left(-\mu^2\frac{\partial}{\partial u^\mu}(\ln u^\mu)\frac{\partial u^\mu}{\partial x}\right)^2 + V(x)\nonumber\\
& = \frac{\mu^2}{2}\left(\frac{\mu^2}{(u^\mu)^2}\left(\frac{\partial u^\mu}{\partial x}\right)^2 - \frac{\mu^2}{u^\mu}\frac{\partial^2 u^\mu}{\partial x^2}\right)\nonumber\\
& = \frac{\mu^2}{2}\frac{\partial}{\partial x}\left(-\frac{\mu^2}{u^\mu}\frac{\partial u^\mu}{\partial x}\right)\nonumber\\
& = \frac{\mu^2}{2}\frac{\partial^2 S^\mu}{\partial x^2}.\nonumber
\end{align}
Also we get the initial condition,
$$
S^\mu(x, 0) = S_0(x) - \mu^2\ln T_0(x).
$$
So in vector calculus notation $S^\mu$ satisfies the Hamilton-Jacobi-Bellman equation,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial S^\mu}{\partial t}(x, t) + \frac{1}{2}\|\nabla S^\mu(x, t)\|^2 + V(x) = \frac{\mu^2}{2}\Delta S^\mu(x, t),\\ \label{HJBE}
& S^\mu(x, 0) = S_0(x) - \mu^2\ln T_0(x).
\end{aligned}
\right.
\end{equation}
If we define $v^\mu(x, t) = \nabla S^\mu(x, t)$ and we take the gradient of \eqref{HJBE},
$$
\nabla\frac{\partial S^\mu}{\partial t} + \frac{1}{2}\nabla\|\nabla S^\mu\|^2 + \nabla V(x) = \frac{\mu^2}{2}\nabla(\Delta S^\mu)
$$
using our definition,
$$
\frac{\partial v^\mu}{\partial t} + \frac{1}{2}\nabla(v^\mu \cdot v^\mu) + \nabla V(x) = \frac{\mu^2}{2}\nabla(\nabla \cdot v^\mu)
$$
which yields,
$$
\frac{\partial v^\mu}{\partial t} + (v^\mu\cdot \nabla)v^\mu + \nabla V(x) = \frac{\mu^2}{2}\Delta v^\mu - \nabla \times (\nabla \times v^\mu).
$$
Since $v^\mu$ is a gradient of a scalar function and the curl of the gradient is zero, we find that $v^\mu$ satisfies,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial v^\mu}{\partial t}(x, t) + (v^\mu\cdot \nabla)v^\mu(x, t) + \nabla V(x) = \frac{\mu^2}{2}\Delta v^\mu(x, t),\\ \label{VBE}
& v^\mu(x, 0) = \nabla S_0(x) - \mu^2\nabla\ln T_0(x),
\end{aligned}
\right.
\end{equation}
which is known as the viscous Burgers' equation.  Similarly, if we define $v = \nabla S$, we find that $v$ satisfies,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial v}{\partial t}(x, t) + (v\cdot \nabla)v(x, t) + \nabla V(x) = 0,\\
& v(x, 0) = \nabla S_0(x),
\end{aligned}
\right.
\end{equation}
the inviscid Burgers' equation.

Given our work on the heat equation we can investigate the asymptotic behaviour of the Burgers' equations.
\corollary
{
Given the no-caustic condition holds with a caustic time $T$, then for all $t \in [0, T)$ we get,
$$
S^\mu(x, t) = S(x, t) - \mu^2\ln\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s) \,\mathrm{d}s\right)\right),
$$
and,
$$
v^\mu(x, t) = v(x, t) - \mu^2\nabla\ln\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \nabla \cdot v(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right)\right),
$$
where $S$ satisfies the Hamilton-Jacobi equation \eqref{HJE}.

Moreover, $\lim_{\mu \to 0}S^\mu(x, t) = S(x, t)$ and $\lim_{\mu \to 0}v^\mu(x, t) = v(x, t)$, for $t \in [0, T)$.
}
\proof
{
From the stochastic elementary formula \eqref{SEF},
\begin{align}
& \,\,S^\mu(x, t)\nonumber\\
= & -\mu^2\ln u^\mu(x, t)\nonumber\\
= & -\mu^2\ln\left(\exp\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right)\right)\right)\nonumber\\
= & -\mu^2\ln\exp\left(-\frac{S(x, t)}{\mu^2}\right)\nonumber\\
& - \mu^2\ln\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s) \,\mathrm{d}s\right)\right)\nonumber\\
= & \,\,S(x, t) - \mu^2\ln\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s) \,\mathrm{d}s\right)\right)\nonumber
\end{align}
Secondly, we take the gradient of both sides,
\begin{align}
v^\mu(x, t) & = \nabla S^\mu(x, t)\nonumber\\
& = \nabla S(x, t) - \mu^2\nabla\ln\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \Delta S(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right)\right)\nonumber\\
& = v(x, t) - \mu^2\nabla\ln\mathbb{E}\left(T_{0}(X^{\mu}_{t})\exp\left(-\frac{1}{2}\int_0^t \nabla \cdot v(X^{\mu}_{s}, t - s)\,\mathrm{d}s\right)\right)\nonumber
\end{align}
The limits $\lim_{\mu \to 0}S^\mu(x, t) = S(x, t)$ and $\lim_{\mu \to 0}v^\mu(x, t) = v(x, t)$ are given by dominated convergence.

\qedhere
}

We are now going to explore an underlying connection between the \\stochastic elementary formula and the continuity equation of the Burgers' fluid.  The connection becomes clearer with the next theorem.
\theorem
{
Given that the no-caustic condition holds for some $T > 0$, we define,
$$
\rho(x, t) = T_0^2(\Phi_t^{-1}(x))|\det D\Phi_t^{-1}(x)|.
$$
Then, assuming that $\rho$ is jointly continuous together with its first order partial derivatives, $\rho$ satisfies the continuity equation,
$$
\frac{\partial \rho}{\partial t}(x, t) + \nabla(\rho(x, t)\nabla S(x, t)) = 0, \hspace{0.3cm} t \in [0, T)
$$
with the initial condition $\rho(x, 0) = T_0^2(x)$.
}
\proof
{
Let us consider the curvilinear tube $\tau_F$ given by the classical mechanical flow map $\Phi_s, 0 \le s\le t < T$ acting on a borel set $F \subset \mathbb{R}^n$.
With the substitution $x = \Phi_t(x_0)$ we get,
$$
\int_{\Phi_t(F)} T_0^2(\Phi_t^{-1}(x))|\det D\Phi_t^{-1}(x)|\,\mathrm{d}x = \int_F T_0^2(x_0)\,\mathrm{d}x_0.
$$
We now introduce a vector field in order to use the divergence theorem,
$$
\mathbf{j}(x, s) = T_0^2(\Phi_t^{-1}(x))|\det D\Phi_t^{-1}(x)|(\nabla S(x, t), 1), \hspace{0.4cm}(x, s) \in \mathbb{R}^n \times \mathbb{R}^+.
$$
We now integrate over the boundary of the tube,
\begin{align}
\int_{\partial \tau_F} \mathbf{j}(x, s)\cdot \mathrm{d}\Sigma & = \int_F \mathbf{j}(x, 0)\cdot(\mathbf{0}, -1)\,\mathrm{d}x + \int_{\Phi_t(F)} \mathbf{j}(x, t)\cdot(\mathbf{0}, 1)\,\mathrm{d}x \nonumber\\
& \hspace{0.4cm} + \int_{\tau_F} \mathbf{j}(x, s)\cdot \mathbf{n}\,\mathrm{d}\Sigma \nonumber\\
& = -\int_F T_0^2(x)\,\mathrm{d}x + \int_{\Phi_t(F)} T_0^2(\Phi_t^{-1}(x))|\det D\Phi_t^{-1}(x)|\,\mathrm{d}x\nonumber\\
& = -\int_F T_0^2(x)\,\mathrm{d}x + \int_F T_0^2(x_0)\,\mathrm{d}x_0\nonumber\\
& = 0\nonumber
\end{align}
where $\mathbf{0} \in \mathbb{R}^n$ is the n-dimensional zero vector and $\mathbf{n}$ is the unit normal vector to the curved surface of $\tau_F$.  This integral is $0$ since the curved surface is parallel to $\nabla S(x, t)$.  Now by the divergence theorem,
$$
\int_{\partial \tau_F} \mathbf{j}(x, s)\cdot \mathrm{d}\Sigma = \int_{\tau_F} \nabla^* \cdot \mathbf{j}(x, s)\,\mathrm{d}x\,\mathrm{d}s = 0
$$
where $\nabla^*\mathbf{j} \cdot = \left(\nabla, \frac{\partial}{\partial s}\right) \cdot\mathbf{j}$.  Finally, since $F$ was arbitrary we can conclude that,
\begin{align}
0 & = \nabla^* \cdot \mathbf{j}(x, s)\nonumber\\
& = \nabla^* \cdot (\rho(x, s)(\nabla S(x, s), 1))\nonumber\\
& = \nabla^* \cdot ((\rho(x, s)\nabla S(x, s), \rho(x, s)))\nonumber\\
& = \left(\nabla, \frac{\partial}{\partial s}\right)\cdot((\rho(x, s)\nabla S(x, s), \rho(x, s)))\nonumber\\
& = \nabla\cdot(\rho(x, s)\nabla S(x, s)) + \frac{\partial \rho}{\partial s}(x, s).\nonumber
\end{align}

\qedhere
}

Thus our Burgers' equation represents a fluid of particles moving according to classical mechanics as we have shown that $v(x, t) = \nabla S(x, t) = \dot{\Phi}_t(\Phi_t^{-1}(x))$. with their density determined by $T_0(x)$.  We now define a new function $\rho_0 = \sqrt{\rho}$.
\theorem
{
Given that the no-caustic condition holds for the caustic time $T > 0$, then,
\begin{equation}
u^\mu(x, t) = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\rho_0(x, t)\mathbb{E}\left(\exp\left(\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(Y_s^\mu, t - s)}{\rho_0(Y_s^\mu, t - s)}\,\mathrm{d}s\right)\right) \label{HOSEF}
\end{equation}
where $X_s^\mu$ satisfies the new SDE,
$$
\left\{
\begin{aligned}
& \mathrm{d}Y_s^\mu = \left(-\nabla S(Y_s^\mu, t - s) + \mu^2\nabla\ln\rho_0(Y_s^\mu, t - s)\right)\mathrm{d}s + \mu\,\mathrm{d}B_s,\\ 
& \hspace{0.2cm} Y_0^\mu = x.
\end{aligned}
\right.
$$
}
\proof
{
We denote $Z_s^\mu = -S(Y_s^\mu, t - s) + \mu^2\ln\rho_0(Y_s^\mu, t - s)$, then our It$\mathrm{\hat{o}}$ diffusion becomes $\mathrm{d}Y_s^\mu = \nabla Z_s^\mu\,\mathrm{d}s + \mu\,\mathrm{d}B_s$.  We will derive a general form of the Radon-Nikodym derivative and substitute in our actual drift.  The calculation follows that of Theorem 6 and we get our Radon-Nikodym derivative given by,
\begin{align}
M_t & = \exp\left(-\frac{1}{\mu}\int_0^t\nabla Z_s^\mu\cdot\mathrm{d}B_s - \frac{1}{\mu^2}\int_0^t\frac{1}{2}\|\nabla Z_s^\mu\|\,\mathrm{d}s\right)\nonumber\\
& = \exp\left(\frac{1}{\mu^2}(Z_0^\mu - Z_t^\mu) + \frac{1}{\mu^2}\int_0^t\left(\frac{\partial Z_s^\mu}{\partial s} + \frac{1}{2}\|\nabla Z_s^\mu\|^2\right)\mathrm{d}s + \frac{1}{2}\int_0^t\Delta Z_s^\mu\,\mathrm{d}s\right)\nonumber
\end{align}
Before we proceed, our continuity equation is given by,
$$
\frac{\partial \rho}{\partial s} + \nabla\cdot(\rho\nabla S) = 0
$$
using our definition $\rho = \rho_0^2$,
$$
\frac{\partial \rho_0^2}{\partial s} + \nabla\rho_0^2\cdot\nabla S + \rho_0^2\Delta S = 0
$$
by some vector calculus our continuity equation has the form,
$$
\frac{1}{\rho_0}\frac{\partial\rho_0}{\partial s} + \frac{\nabla\rho_0}{\rho_0}\cdot\nabla S + \frac{1}{2}\Delta S = 0.
$$

From here we proceed by direct computation of each term of $M_t$,
$$
\frac{1}{\mu^2}(Z_0^\mu - Z_t^\mu) = \frac{1}{\mu^2}(S_0(X_t^\mu) - S(x, t)) + \ln\frac{\rho_0(x, t)}{T_0(X_t^\mu)}
$$
using our modified continuity equation and the Hamilton-Jacobi equation \eqref{HJE},
\begin{align}
\frac{1}{\mu^2}\left(\frac{\partial Z_s^\mu}{\partial s} + \frac{1}{2}\|\nabla Z_s^\mu\|^2\right) & = \frac{1}{\mu^2}\left(\frac{\partial S}{\partial t} + \frac{1}{2}\|\nabla S\|^2\right) - \frac{1}{\rho_0}\left(\frac{\partial\rho_0}{\partial t} + \nabla\rho_0\cdot\nabla S\right)\nonumber\\
& \hspace{0.5cm} + \frac{\mu^2}{2}\frac{\|\nabla\rho_0\|^2}{\rho_0^2}\nonumber\\
& = -\frac{1}{\mu^2}V + \frac{1}{2}\Delta S + \frac{\mu^2}{2}\frac{\|\nabla\rho_0\|^2}{\rho_0^2}\nonumber
\end{align}
and by vector calculus,
\begin{align}
\frac{1}{2}\Delta Z_s^\mu & = -\frac{1}{2}\Delta S + \frac{\mu^2}{2}\nabla\cdot\left(\rho_0^{-1}\nabla\rho_0\right)\nonumber\\
& = -\frac{1}{2}\Delta S + \frac{\mu^2}{2}(\nabla\rho_0^{-1}\cdot\nabla\rho_0 + \rho_0^{-1}\nabla\cdot(\nabla\rho_0))\nonumber\\
& = -\frac{1}{2}\Delta S - \frac{\mu^2}{2}\frac{\|\nabla\rho_0^2\|}{\rho_0^2} + \frac{\mu^2}{2}\frac{\Delta\rho_0}{\rho_0}.\nonumber
\end{align}
So we get,
\begin{align}
M_t & = \exp\left(\frac{1}{\mu^2}(S_0(X_t^\mu) - S(x, t))\right.\nonumber\\
& \hspace{0.75cm} + \ln\frac{\rho_0(x, t)}{T_0(X_t^\mu)} + \int_0^t\left(-\frac{1}{\mu^2}V(X_s^\mu) + \left.\frac{\mu^2}{2}\frac{\Delta\rho_0(X_s^\mu, t - s)}{\rho_0(X_s^\mu, t - s)}\right)\mathrm{d}s\right)\nonumber
\end{align}
Using the Cameron-Martin change of measure we get the required result,
\begin{align}
u^\mu(x, t) & = \mathbb{E}\left(T_0(X_t^\mu)\exp\left(-\frac{1}{\mu^2}S_0(X_t^\mu) + \frac{1}{\mu^2}\int_0^tV(X_t^\mu)\,\mathrm{d}s\right)M_t\right)\nonumber\\
& = \mathbb{E}\left(T_0(X_t^\mu)\exp\left(-\frac{S(x, t)}{\mu^2}\right.\right.\nonumber\\
& \hspace{0.5cm} + \left.\left.\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(X_s^\mu, t - s)}{\rho_0(X_s^\mu, t - s)}\,\mathrm{d}s + \ln\frac{\rho_0(x, t)}{T_0(X_t^\mu)}\right)\right)\nonumber\\
& = \mathbb{E}\left(\rho_0(x, t)\exp\left(-\frac{S(x, t)}{\mu^2}\right)\exp\left(\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(X_s^\mu, t - s)}{\rho_0(X_s^\mu, t - s)}\,\mathrm{d}s\right)\right)\nonumber\\
& = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\rho_0(x, t)\mathbb{E}\left(\exp\left(\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(X_s^\mu, t - s)}{\rho_0(X_s^\mu, t - s)}\,\mathrm{d}s\right)\right).\nonumber
\end{align}

\qedhere
}

\corollary
{
Given that the no-caustic condition holds for the caustic time $T$ as before and that $\frac{\Delta \rho_0}{\rho_0}(x, t)$ is bounded for $t \in (0, T)$, then we have,
\begin{align}
u^\mu(x, t) = \exp & \left(-\frac{S(x, t)}{\mu^2}\right)T_0(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}\nonumber\\
& \hspace{1.1cm} \times\left(1 + \frac{\mu^2}{2}\int_0^t\frac{\Delta \rho_0(\Phi_{t - s}(\Phi_t^{-1}(x)), t - s)}{\rho_0(\Phi_{t - s}(\Phi_t^{-1}(x)), t - s)}\,\mathrm{d}s + \mathcal{O}(\mu^2)\right)\nonumber
\end{align}
for all $t \in [0, T)$.
}
\proof
{
Recall that we deduced $X_s^\mu = \Phi_{t - s}(\Phi_t^{-1}(x))$ and remember $\rho_0(x, t) = \sqrt{\rho(x, t)} = T_0(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}$.  Furthermore, we use the Taylor expansion of the exponential function given by,
$$
\exp(x) = \sum_{n = 0}^\infty \frac{x^n}{n!}.
$$
So the first few terms of $\exp\left(\frac{\Delta\rho_0}{\rho_0}\right)$ is given by,
$$
\exp\left(\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0}{\rho_0}(X_s^\mu, t - s)\,\mathrm{d}s\right) = 1 + \frac{\mu^2}{2}\int_0^t\frac{\Delta \rho_0(X_s^\mu, t - s)}{\rho_0(X_s^\mu, t - s)}\,\mathrm{d}s + \mathcal{O}(\mu^2).
$$
Substituting the above expressions into \eqref{HOSEF} from Theorem 9 trivially gives us the desired result.

\qedhere
}

This corollary gives us an extension to Corollary 1 in terms of order $\mu^2$.  This can be extended to higher order terms (see A. Truman and H. Z. Zhao \cite{ATHZZ}).








\chapter{Heat Equation with Vector Potential}

In this chapter we are going to apply the methods used in Chapter 2 to a new heat equation with vector potential $\mathbf{a} : \mathbb{R}^3 \times [0, \infty) \to \mathbb{R}^3$.  Let $u^\mu : \mathbb{R}^3 \times [0, \infty) \to \mathbb{R}$ be the solution to,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial u^\mu}{\partial t}(x, t) = \frac{\mu^2}{2}\Delta u^\mu(x, t) + \mathbf{a}(x, t)\cdot\nabla u^\mu(x, t) + \frac{1}{\mu^2}\bar{V}(x, t)u^\mu(x, t),\\ \label{VPHE}
& u^\mu(x, 0) = T_0(x)\exp\left(-\frac{S_0(x)}{\mu^2}\right).
\end{aligned}
\right.
\end{equation}
Note here our new potential $\bar{V}$ depends on time as well as our standard spacial variable $x$, given explicitly
$$
\bar{V}(x, t) = \frac{1}{2}\|\mathbf{a}(x, t)\|^2 + \frac{\mu^2}{2}\nabla\cdot\mathbf{a}(x, t) + V(x)
$$
where $S_{0}, T_{0}, V:\mathbb{R}^3  \to \mathbb{R}$ and $\|\cdot\|$ denotes the Euclidean norm on $\mathbb{R}^3$.
\assumption
{
We assume that:
\begin{enumerate}
\item $V$, $S_0$, $T_0$ and the elements of $\mathbf{a}$ are real-valued.
\item $V$ and $\mathbf{a}$ are globally Lipschitz in the spatial variable.
\item $V$ is bounded below, $S_0$ is bounded above, $T_0$ is positive and bounded and $\mathbf{a}$ is bounded.
\item The first and second order partial derivatives of $V$, $S_0$ and the elements of $\mathbf{a}$ are uniformly bounded on $\mathbb{R}^3$.
\end{enumerate}
}

Due to the time dependency of the new potential we cannot use our standard solution using the Feynman-Kac Formula for initial value problems \eqref{FCF}.  We follow \cite{ANSRAT} throughout this chapter and instead consider the Feynman-Kac Formula for boundary valued problems given in equation \eqref{DPFCF}.  If we consider time to be an extra spatial dimension with an appropriate boundary condition set at $t = 0$ then we may solve \eqref{VPHE}.  We define our diffusion,
$$
\left\{
\begin{aligned}
& \mathrm{d}X_s^\mu = \mathbf{a}(X_s^\mu, T_s^t)\,\mathrm{d}s + \mu\,\mathrm{d}B_s, \hspace{0.3cm} T_s^t = t - s, \hspace{0.3cm} s \in [0, t],\\
& \hspace{0.2cm} X_0^\mu = x,
\end{aligned}
\right.
$$
where, $B_s$ is a 3-dimensional Brownian Motion.
\theorem
{
Let $u^\mu$ be a solution to \eqref{VPHE} that is continuous and bounded on $\mathbb{R}^3 \times [0, T]$, for all $T > 0$.  Assume that the derivatives of $u^\mu$ are bounded and continuous in $\mathbb{R}^3 \times (h, T)$, for all $h \in (0, T)$ up to second order in space and first order in time. Then
\begin{equation}
u^\mu(x, t) = \mathbb{E}\left(T_0(X_s^\mu)\exp\left(-\frac{1}{\mu^2}S_0(X_t^\mu) + \frac{1}{\mu^2}\int_0^t\bar{V}(X_s^\mu, t - s)\,\mathrm{d}s\right)\right). \label{FCF2}
\end{equation}
}
\proof
{
We define a new diffusion by,
$$
\tilde{X}_s^\mu = \begin{pmatrix} X_s^\mu \\  T_s^t \end{pmatrix}, \hspace{0.4cm} \tilde{X}_0^\mu = \begin{pmatrix} x \\ t\end{pmatrix}.
$$
Now,
\begin{align}
\mathrm{d}\tilde{X}_s^\mu & = \begin{pmatrix} \mathrm{d}X_s^\mu \\  \mathrm{d}T_s^t \end{pmatrix}\nonumber\\
& = \begin{pmatrix} \mathbf{a}(\tilde{X}_s^\mu)\,\mathrm{d}s + \mu\,\mathrm{d}B_s \\  -\mathrm{d}s\end{pmatrix}\nonumber\\
& = \begin{pmatrix} \mathbf{a}(\tilde{X}_s^\mu) \\ -1 \end{pmatrix}\mathrm{d}s + \mu\begin{pmatrix} I_3 & 0 \\ 0 & 0 \end{pmatrix}\begin{pmatrix} \mathrm{d}B_s \\ \mathrm{d}B_s^T \end{pmatrix}\nonumber\\
& = \tilde{\mathbf{a}}(\tilde{X}_s^\mu)\,\mathrm{d}s + \tilde{\mu}\,\mathrm{d}\tilde{B}_s\nonumber
\end{align}
where $B_s^T$ is a 1-dimensional Brownian Motion, $I_3$ is the $3 \times 3$ identity matrix and,
$$
\tilde{\mathbf{a}}(\tilde{X}_s^\mu) = \begin{pmatrix} \mathbf{a}(\tilde{X}_s^\mu) \\ -1 \end{pmatrix}, \hspace{0.3cm} \tilde{\mu} = \mu\begin{pmatrix} I_3 & 0 \\ 0 & 0 \end{pmatrix}, \hspace{0.3cm} \tilde{B}_s = \begin{pmatrix} B_s \\  B_s^T \end{pmatrix}.
$$
We now call upon the result of Theorem 3.  We define our domain as $D = \mathbb{R}^3 \times \mathbb{R}^+$ and clearly this has boundary $\partial D = \mathbb{R}^3 \times \{0\}$.  Assuming $X_s^\mu$ is bounded and well-defined for $s \in [0, t]$, we also have,
$$
\tau_D^{(x, t)} = \inf\{s : \tilde{X}_s^\mu \in \partial D\} = t
$$
since, when $s = t$,
$$
\tilde{X}_t^\mu = (X_t^\mu, 0) \in \partial D.
$$
Finally, if we define $\tilde{x} = (x, t)$, we can re-write \eqref{VPHE} as,
$$
\frac{\partial u^\mu}{\partial t}(\tilde{x}) = \frac{\mu^2}{2}\Delta u^\mu(\tilde{x}) + \mathbf{a}(\tilde{x})\cdot\nabla u^\mu(\tilde{x}) + \frac{1}{\mu^2}\bar{V}(\tilde{x})u^\mu(\tilde{x}).
$$
or,
$$
0 = \left(\frac{1}{2}\sum_{i, j = 1}^{n + 1}\tilde{\mu}_{ij}^2\frac{\partial^2}{\partial x_i \partial x_j} + \sum_{i = 1}^{n + 1}\tilde{a}_i(\tilde{x})\frac{\partial}{\partial x_i}\right)u^\mu(\tilde{x}) + \frac{1}{\mu^2}\bar{V}(\tilde{x})u^\mu(\tilde{x})
$$
which has the boundary condition,
$$
\lim_{\tilde{x} \to (x, 0)} u^\mu(\tilde{x}) = T_0(x)\exp\left(-\frac{S_0(x)}{\mu^2}\right), \hspace{0.2cm} \tilde{x} \in D, \hspace{0.2cm} x \in \mathbb{R}^3.
$$
Therefore, from Theorem 3 our solution is given by,
$$
u^\mu(\tilde{x}) = \mathbb{E}\left(T_0(X_t^\mu)\exp\left(-\frac{S_0(X_t^\mu)}{\mu^2} + \int_0^t\bar{V}(X_s^\mu, t - s)\,\mathrm{d}s\right)\right).\nonumber
$$

\qedhere
}

Theorem 10 shows that time needs to be reversed in the time dependent potentials in order to meet the boundary conditions at $t = 0$.

As in the previous chapter, we take advantage of the underlying mechanical system for our calculations.  The first thing to introduce is the classical mechanical flow map $\Phi_t : \mathbb{R}^3 \to \mathbb{R}^3$, $t \in [0, \infty)$, defined by the second order differential equation,
\begin{equation}
\left\{
\begin{aligned}
\ddot{\Phi}_t(x) & = -\nabla V(\Phi_t(x)) - \frac{\partial \mathbf{a}}{\partial t}(\Phi_t(x), t) - (\nabla \times \mathbf{a}(\Phi_t(x), t))\times\dot{\Phi}_t(x),\\ \label{CMFM2}
\dot{\Phi}_0(x) & = \nabla S_0(x) - \mathbf{a}(x, 0),\\
\Phi_0(x) & = x.
\end{aligned}
\right.
\end{equation}
This can be thought of as the classical mechanical flow map describing the position of a charged particle moving under an electric potential $V$ and a vector potential $\mathbf{a}$ giving rise to an electric field $\mathbf{E}(x, t) = -\nabla V(x) - \frac{\partial \mathbf{a}}{\partial t}(x, t)$ and a magnetic field $\mathbf{B}(x, t) = \nabla \times \mathbf{a}(x, t)$.

\theorem
{
Suppose that,
\begin{equation}
\frac{\partial^2 a_i}{\partial x_j \partial x_k} = \frac{\partial^2 a_k}{\partial x_i \partial x_j}, \hspace{0.3cm} \text{for } i, j, k \in \{1, 2, 3\}. \label{MFC}
\end{equation}
Then, $\Phi_t$ satisfies the no-caustic condition for the caustic time $T > 0$.
}
\proof
{
Similarly to Theorem 9, from the definition of $\Phi_t$ \eqref{CMFM2} we get,
\begin{align}
\Phi_t(x) & = x + t(\nabla S_0(x) - \mathbf{a}(x, 0)) - \int_0^t\int_0^s\nabla V(\Phi_r(x))\,\mathrm{d}r\,\mathrm{d}s\nonumber\\
& \hspace{0.1cm} - \int_0^t\int_0^s\frac{\partial \mathbf{a}}{\partial r}(\Phi_r(x), r)\,\mathrm{d}r\,\mathrm{d}s - \int_0^t\int_0^s\nabla\times(\mathbf{a}(\Phi_r(x), r)\times\dot{\Phi}_r(x))\,\mathrm{d}r\,\mathrm{d}s.\nonumber
\end{align}
Taking the Fr$\mathrm{\acute{e}}$chet derivative leaves us with,
\begin{align}
D\Phi_t(x) & = I_3 + tM(x) - \int_0^tN(\Phi_s(x), s)D\Phi_s(x)\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} - \int_0^t\int_0^sP(\Phi_r(x), r)D\Phi_r(x)\,\mathrm{d}r\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \int_0^t\int_0^sQ(\Phi_r(x), \dot{\Phi}_r(x), r)D\Phi_r(x)\,\mathrm{d}r\,\mathrm{d}s\nonumber
\end{align}
where $M$, $N$, $P$ and $Q$ are the $3 \times 3$ matrices with elements,
$$
M_{ij}(x) = \frac{\partial^2S_0}{\partial x_i \partial x_j}(x) - \frac{\partial a_j}{\partial x_i}(x, 0),
$$
$$
N_{ij}(x, t) = \frac{\partial a_j}{\partial x_i}(x, t) - \frac{\partial a_i}{\partial x_j}(x, t),
$$
$$
P_{ij}(x, t) = \frac{\partial^2V}{\partial x_i \partial x_j}(x) + \frac{\partial^2a_j}{\partial x_i \partial t}(x, t),
$$
$$
Q_{ij}(x, \dot{x}, t) = \sum_{k = 1}^3\dot{x}_k\left(\frac{\partial^2a_k}{\partial x_i \partial x_j}(x, t) - \frac{\partial^2a_i}{\partial x_j \partial x_k}(x, t)\right).
$$

By our supposition $Q = 0$ and it follows that there exists $T > 0$ such that for all $\varepsilon\in(0, 1)$,
\begin{align}
& \left\|tM(x) - \int_0^tN(\Phi_s(x), s)D\Phi_s(x)\,\mathrm{d}s\right.\nonumber\\
& \hspace{2cm} + \left.\int_0^t\int_0^sP(\Phi_r(x), r)Q(\Phi_r(x))\,\mathrm{d}r\,\mathrm{d}s\right\| < \varepsilon, \hspace{0.3cm} t \in [0, T).\nonumber
\end{align}
So, $0 < \|D\Phi_t(x)\| \le 1 + \varepsilon$ and $D\Phi_t(x)$ is invertible by the property of matrices used in Theorem 5 and we get,
$$
\|D\Phi_t(x)^{-1}\| < (1 - \varepsilon)^{-1} \Leftrightarrow \|D\Phi_t(x)^{-1}v\| \le (1 - \varepsilon)^{-1}\|v\|
$$
where $v \in \mathbb{R}^3$. Setting $v = D\Phi_t(x)y$ gives us $(1 - \varepsilon)\|y\| \le \|D\Phi_t(x)y\|$.  Since $1 - \varepsilon > 0$ and $\Phi_t$ is homotopic to the identity mapping since $\Phi_0(x) = x$, the Global Inverse Function Theorem (Theorem 4) gives the result.

\qedhere
}

\begin{remark}
{
Our condition \eqref{MFC} gives us,
$$
\frac{\partial^2 a_i}{\partial x_j \partial x_k} = \frac{\partial^2 a_k}{\partial x_i \partial x_j}, \hspace{0.3cm} \text{for } i, j, k \in \{1, 2, 3\}.
$$
Assuming $\mathbf{a}$ is sufficiently well-behaved we can change the order of differentiation to get,
$$
\frac{\partial}{\partial x_j}\left(\frac{\partial a_i}{\partial x_k} - \frac{\partial a_k}{\partial x_i}\right) = 0
$$
which is equivalent to,
$$
\nabla\cdot\left(\nabla\times\mathbf{a}\right) = 0 \hspace{0.3cm} \Leftrightarrow \hspace{0.3cm} \nabla\cdot\mathbf{B} = 0
$$
where $\mathbf{B}$ is our magnetic field.  This shows that the condition imposed is equivalent to the magnetic field being divergence free which includes the case of $\mathbf{B}$ being constant.
}
\end{remark}

Following Chapter 2 we want to define our new action functional but incorporating our vector potential $\mathbf{a}$.  Define,
\begin{align}
\mathscr{A}(x, t) & = S_0(x) + \int_0^t\mathscr{L}(\Phi_s(x), \dot{\Phi}_s(x))\,\mathrm{d}s\nonumber\\
& = S_0(x) + \frac{1}{2}\int_0^t\|\dot{\Phi}_s(x)\|^2\,\mathrm{d}s\nonumber\\
& \hspace{1.6cm} + \int_0^t\dot{\Phi}_s(x)\cdot\mathbf{a}(\Phi_s(x), s)\,\mathrm{d}s - \int_0^tV(\Phi_s(x))\,\mathrm{d}s\nonumber
\end{align}
where $\mathscr{L}$ is this system's Lagrangian.  Before moving on we need some properties of $\mathscr{A}$ and $\Phi_t$ presented in the following lemmas.
\lemma
{
Given that the no-caustic condition holds for a caustic time $T$, we have that for all $t \in [0, T)$,
$$
\nabla\mathscr{A}(x, t) = (D\Phi_t(x))^*(\dot{\Phi}_t(x) + \mathbf{a}(\Phi_t(x), t))
$$
where * denotes matrix transpose.
}
\proof
{
Firstly,
\begin{align}
\nabla\mathscr{A}(x, t) & = \nabla S_0(x) + \int_0^t(D\Phi_s(x))^*(\dot{\Phi}_s(x) + \mathbf{a}(\Phi_s(x), s))\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \int_0^t(D\mathbf{a}(\Phi_s(x), s))^*\dot{\Phi}_s(x)\,\mathrm{d}s - \int_0^t(D\Phi_s(x))^*\nabla V(\Phi_s(x))\,\mathrm{d}s.\nonumber
\end{align}
Using integration by parts,
\begin{align}
\int_0^t\frac{\mathrm{d}}{\mathrm{d}s}(D\Phi_s&(x))^*(\dot{\Phi}_s(x) + \mathbf{a}(\Phi_s(x), s))\,\mathrm{d}s\nonumber\\
& = \left.(D\Phi_s(x))^*(\dot{\Phi}_s(x) + \mathbf{a}(\Phi_s(x), s))\right|_{s = 0}^{s = t}\nonumber\\
& \hspace{0.4cm} - \int_0^t(D\Phi_s(x))^*\left(\ddot{\Phi}_s + \frac{\mathrm{d}}{\mathrm{d}s}\mathbf{a}(\Phi_s(x), s)\right)\mathrm{d}s\nonumber\\
& = (D\Phi_t(x))^*(\dot{\Phi}_t(x) + \mathbf{a}(\Phi_t(x), t)) - \nabla S_0(x)\nonumber\\
& \hspace{0.4cm} - \int_0^t(D\Phi_s(x))^*\left(\ddot{\Phi}_s + D\mathbf{a}(\Phi_s(x), s)\dot{\Phi}_s(y) + \frac{\partial\mathbf{a}}{\partial s}(\Phi_s(x), s)\right)\mathrm{d}s\nonumber
\end{align}
and so,
\begin{align}
\nabla S_0(x) & = (D\Phi_t(x))^*(\dot{\Phi}_t(x) + \mathbf{a}(\Phi_t(x), t))\nonumber\\
& \hspace{0.5cm} - \int_0^t(D\Phi_s(x))^*\left(\ddot{\Phi}_s + D\mathbf{a}(\Phi_s(x), s)\dot{\Phi}_s(y) + \frac{\partial\mathbf{a}}{\partial s}(\Phi_s(x), s)\right)\mathrm{d}s\nonumber\\
& \hspace{0.5cm} - \int_0^t(D\dot{\Phi}_s(x))^*(\dot{\Phi}_s(x) + \mathbf{a}(\Phi_s(x), s))\,\mathrm{d}s\nonumber
\end{align}
hence,
\begin{align}
\nabla\mathscr{A} & (x, t) = (D\Phi_t(y))^*(\dot{\Phi}_t(x) + \mathbf{a}(\Phi_t(x), t))\nonumber\\
& - \int_0^t(D\Phi_s(y))^*\left(\ddot{\Phi}_s(x) + \frac{\partial\mathbf{a}}{\partial s}(\Phi_s(x), s) + D\mathbf{a}(\Phi_s(x), s)\dot{\Phi}_s(x)\right)\,\mathrm{d}s\nonumber\\
& + \int_0^t(D\mathbf{a}(\Phi_s(x), s))^*\dot{\Phi}_s(x)\,\mathrm{d}s - \int_0^t\nabla V(\Phi_s(x))\,\mathrm{d}s.\nonumber
\end{align}
Now,
$$
\ddot{\Phi}_s(x) = -\nabla V(\Phi_s(x)) - \frac{\partial \mathbf{a}}{\partial s}(\Phi_s(x), s) - (\nabla \times \mathbf{a}(\Phi_s(x), s))\times\dot{\Phi}_s(x)
$$
thus,
\begin{align}
\nabla\mathscr{A} & (x, t) = (D\Phi_t(y))^*(\dot{\Phi}_t(x) + \mathbf{a}(\Phi_t(x), t))\nonumber\\
& - \int_0^t(D\Phi_s(y))^*(- (\nabla \times \mathbf{a}(\Phi_s(x), s))\times\dot{\Phi}_s(x) + D\mathbf{a}(\Phi_s(x), s)\dot{\Phi}_s(x))\,\mathrm{d}s\nonumber\\
& + \int_0^t(D\mathbf{a}(\Phi_s(x), s))^*\dot{\Phi}_s(x)\,\mathrm{d}s\nonumber
\end{align}
However,
$$
(\nabla\times\mathbf{a}(\Phi_s(x), s))\times\dot{\Phi}_s(x) = D\mathbf{a}(\Phi_s(x), s))\dot{\Phi}_s(x) - D\mathbf{a}(\Phi_s(x), s))^*\dot{\Phi}_s(x)
$$
and so,
\begin{align}
\nabla\mathscr{A}(x, t) & = (D\Phi_t(y))^*(\dot{\Phi}_t(x) + \mathbf{a}(\Phi_t(x), t)) + \int_0^t(D\mathbf{a}(\Phi_s(x), s))^*\dot{\Phi}_s(x)\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} - \int_0^t(D\Phi_s(x))^*D\mathbf{a}(\Phi_s(x), s)^*\dot{\Phi}_s(x)\,\mathrm{d}s.\nonumber
\end{align}
From here the result follows from the chain rule.

\qedhere
}
\lemma
{
Assume $\Phi_t$ satisfies the no-caustic condition for the caustic time $T$.  Then $\Phi_t^{-1}$ satisfies,
$$
\left\{
\begin{aligned}
\frac{\mathrm{d}\Phi_t^{-1}}{\mathrm{d}t} & = -(D\Phi_t)^{-1}\dot{\Phi}_t(\Phi_t^{-1}), \hspace{0.3cm} t \in [0, T),\\
\Phi_0^{-1}(x) & = x.
\end{aligned}
\right.
$$
}
\proof
{
By definition $\Phi_t^{-1}(\Phi_t(x)) = x$, so,
$$
\frac{\mathrm{d}}{\mathrm{d}t}(\Phi_t^{-1}(\Phi_t(x))) = \frac{\mathrm{d}x}{\mathrm{d}t} = 0
$$
and by the chain rule,
$$
\frac{\partial\Phi_t^{-1}}{\partial t}(\Phi_t(x)) + D\Phi_t^{-1}(\Phi_t(x))\frac{\partial\Phi_t}{\partial t}(x) = 0.
$$
Setting $\Phi_t(x) = y$,
$$
\frac{\partial\Phi_t^{-1}}{\partial t}(y) + (D\Phi_t)^{-1}\dot{\Phi}(\Phi_t^{-1}(y)) = 0.
$$
Also by definition, $\Phi_0(x) = x$ which is equivalent to $\Phi_0^{-1}(x) = x$, giving us the result.

\qedhere
}

These lemmas and the definition $S(x, t) = \mathscr{A}(\Phi_t^{-1}(x), t)$ put us in a position for one more necessary theorem before continuing.
\theorem
{
Assume $\Phi_t$ satisfies the no-caustic condition with the caustic time $T > 0$, then for $0 \le t < T$:
\begin{enumerate}
\item $\dot{\Phi}_t$ is given by,
$$
\dot{\Phi}_t(x) = \nabla S(\Phi_t(x), t) - \mathbf{a}(\Phi_t(x), t).
$$
\item $S$ satisfies the Hamilton-Jacobi equation,
\begin{equation}
\frac{\partial S}{\partial t}(x, t) + \frac{1}{2}\|\nabla S(x, t) - \mathbf{a}(x, t)\|^2 + V(x) = 0. \label{HJE2}
\end{equation}
\item If we define,
$$
\rho(x, t) = T_0^2(\Phi_t^{-1}(x))|\det(D\Phi_t^{-1}(x))|
$$
then $\rho$ satisfies the new continuity equation,
\begin{equation}
\frac{\partial \rho}{\partial t}(x, t) + \nabla(\rho(x, t)(\nabla S(x, t) - \mathbf{a}(x, t))) = 0 \label{CE2}
\end{equation}
with the initial condition $\rho(x, 0) = T_0^2(x)$.
\end{enumerate}
}
\proof
{
For part 1 we use the result of Lemma 6,
\begin{align}
\nabla S(y, t) & = \nabla_y\mathscr{A}(\Phi_t^{-1}(y), t)\nonumber\\
& = (D\Phi_t^{-1}(y))^*((D\Phi_t)(\Phi_t^{-1}(y)))^*(\dot{\Phi}_t(\Phi_t^{-1}(y)) + \mathbf{a}(\Phi_t(\Phi_t^{-1}(y)), t))\nonumber
\end{align}
By taking the transpose of,
$$
I = Dy = D(\Phi_t(\Phi_t^{-1}(y))) = (D\Phi_t^{-1}(y))((D\Phi_t)(\Phi_t^{-1}(y)))
$$
and setting $y = \Phi_t(x)$ gives the result,
$$
\dot{\Phi}_t(x) = \nabla S(\Phi_t(x), t) - \mathbf{a}(\Phi_t(x), t).
$$
For part 2, since $x$ is fixed,
$$
\frac{\mathrm{d}S}{\mathrm{d}t}(x, t) = \frac{\partial S}{\partial t}(x, t)
$$
also,
\begin{align}
\frac{\mathrm{d}S}{\mathrm{d}t}(x, t) & = \frac{\mathrm{d}}{\mathrm{d}t}\mathscr{A}(\Phi_t^{-1}(x), t)\nonumber\\
& = \frac{\partial\mathscr{A}}{\partial t}(\Phi_t^{-1}(x), t)\frac{\mathrm{d}t}{\mathrm{d}t} + \nabla\mathscr{A}(\Phi_t^{-1}(x), t)\frac{\mathrm{d}\Phi_t^{-1}}{\mathrm{d}t}\nonumber\\
& = \frac{\partial\mathscr{A}}{\partial t}(\Phi_t^{-1}(x), t) - (D\Phi_t^{-1}(y))^*\nabla\mathscr{A}(\Phi_t^{-1}(x), t)\cdot\dot{\Phi}(\Phi_t^{-1}(x))\nonumber\\
& = \frac{\partial\mathscr{A}}{\partial t}(\Phi_t^{-1}(x), t)\nonumber\\
& \hspace{0.5cm} - (D\Phi_t^{-1}(y))^*(\dot{\Phi}(\Phi_t^{-1}(x)) + \mathbf{a}(\Phi_t(\Phi_t^{-1}(x)), t))\cdot\dot{\Phi}(\Phi_t^{-1}(x))\nonumber\\
& = \frac{\partial\mathscr{A}}{\partial t}(\Phi_t^{-1}(x), t) - \nabla S(x, t)\cdot(\nabla S(x, t) - \mathbf{a}(x, t))\nonumber\\
& = \frac{1}{2}\|\nabla S(x, t)\|^2 - \frac{1}{2}\|\mathbf{a}\|^2 - V(x) - \|\nabla S(x, t)\|^2 + \nabla S(x, t)\cdot\mathbf{a}(x, t)\nonumber\\
& = -\frac{1}{2}\|\nabla S(x, t) - \mathbf{a}(x, t)\|^2 - V(x).\nonumber
\end{align}
Equating the above two expressions gives the result.

Finally for part 3 we take an arbitrary smooth function $f: \mathbb{R}^3 \to \mathbb{R}$ and use integration by parts,
\begin{align}
& \hspace{0.5cm} \int_{\mathbb{R}^3}\int_0^tf(x)\nabla\cdot(\rho(x, s)(\nabla S(x, s) - \mathbf{a}(x, s)))\,\mathrm{d}s\,\mathrm{d}x\nonumber\\
& = - \int_{\mathbb{R}^3}\int_0^t\rho(x, s)\nabla f(x)\cdot(\nabla S(x, s) - \mathbf{a}(x, s))\,\mathrm{d}s\,\mathrm{d}x\nonumber\\
& = - \int_{\mathbb{R}^3}\int_0^t\rho(\Phi_s(y), s)\nabla f(\Phi_s(y))\cdot(\nabla S(\Phi_s(y), s) - \mathbf{a}(\Phi_s(y), s))\,\mathrm{d}s\,\mathrm{d}y\nonumber\\
& = - \int_{\mathbb{R}^3}\int_0^tT_0^2(y)\nabla f(\Phi_s(y))\cdot\dot{\Phi}_s(y)\,\mathrm{d}s\,\mathrm{d}y.\nonumber
\end{align}
By the chain rule,
$$
\frac{\mathrm{d}f}{\mathrm{d}s}(\Phi_s(y)) = \nabla f(\Phi_s(y))\cdot\frac{\mathrm{d}\Phi_s}{\mathrm{d}s}(y) = \nabla f(\Phi_s(y))\cdot\dot{\Phi}_s(y).
$$
So,
\begin{align}
& \hspace{0.5cm} \int_{\mathbb{R}^3}\int_0^tf(x)\nabla\cdot(\rho(x, s)(\nabla S(x, s) - \mathbf{a}(x, s)))\,\mathrm{d}s\,\mathrm{d}x\nonumber\\
& = - \int_{\mathbb{R}^3}\int_0^tT_0^2(y)\,\mathrm{d}f(\Phi_s(y))\,\mathrm{d}y\nonumber\\
& = - \int_{\mathbb{R}^3}T_0^2(y)f(\Phi_t(y))\,\mathrm{d}y + \int_{\mathbb{R}^3}T_0^2(y)f(y)\,\mathrm{d}y\nonumber\\
& = - \int_{\mathbb{R}^3}\int_0^tf(x)\frac{\partial\rho}{\partial s}(x, s)\,\mathrm{d}s\,\mathrm{d}x.\nonumber
\end{align}
Since $f$ was arbitrary we have,
$$
-\frac{\partial\rho}{\partial s}(x, s) = \nabla\cdot(\rho(x, s)(\nabla S(x, s) - \mathbf{a}(x, s))).
$$

\qedhere
}

We are now in a position to show that the stochastic elementary formula holds for this system.
\theorem
{
Given that the no-caustic condition holds for the caustic time $T > 0$, then for $t \in [0, T)$,
\begin{align}
& \hspace{0.5cm} u^\mu(x, t)\nonumber\\
& = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})(Y_s^\mu, t - s)\,\mathrm{d}s\right)\right) \label{SEF2}
\end{align}
where $Y_s^\mu$ satisfies the S.D.E.,
$$
\left\{
\begin{aligned}
\mathrm{d}Y_s^\mu & = -(\nabla S(Y_s^\mu, t - s) - \mathbf{a}(Y_s^\mu, t - s))\,\mathrm{d}s + \mu\,\mathrm{d}B_s, \hspace{0.3cm} s \in [0, t],\\
Y_0^\mu & = x.
\end{aligned}
\right.
$$
}
\proof
{
We proceed in a similar fashion to Theorems 6 and 9.  We use the Cameron-Martin change of measure, our Radon-Nikodym derivative is given by,
$$
M_t = \exp\left(\frac{1}{\mu^2}\int_0^t\nabla S(Y_s^\mu, t - s)\cdot\mathrm{d}B_s - \frac{1}{2\mu^2}\int_0^t\|\nabla S(Y_s^\mu, t - s)\|^2\,\mathrm{d}s\right).
$$
We again apply It$\mathrm{\hat{o}}$'s formula to $S$,
$$
\mathrm{d}S(Y_s^\mu, t -s) = -\frac{\partial S}{\partial t}\,\mathrm{d}s + \sum_{i = 1}^n\frac{\partial S}{\partial x_i}\,\mathrm{d}Y_s^i + \frac{1}{2}\sum_{i, j = 1}^n\frac{\partial^2 S}{\partial x_i \partial x_j}\,\mathrm{d}Y_s^i\,\mathrm{d}Y_s^j
$$
where, $\mathrm{d}Y_s^i = -\frac{\partial S}{\partial x_i}\,\mathrm{d}s + a_i\,\mathrm{d}s + \mu\,\mathrm{d}B_s^i$.

As before,
$$
\mathrm{d}Y_s^i\,\mathrm{d}Y_s^j = 0, \hspace{0.5cm} \mathrm{d}Y_s^i\,\mathrm{d}Y_s^i = \mu^2\,\mathrm{d}s
$$
hence,
\begin{align}
\mathrm{d}S & = -\frac{\partial S}{\partial t}\,\mathrm{d}s - \sum_{i = 1}^n\frac{\partial S}{\partial x_i}\frac{\partial S}{\partial x_i}\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \sum_{i = 1}^na_i\frac{\partial S}{\partial x_i}\,\mathrm{d}s + \mu\sum_{i = 1}^n\frac{\partial S}{\partial x_i}\,\mathrm{d}B_s^i + \frac{\mu^2}{2}\sum_{i, j = 1}^n\frac{\partial^2 S}{\partial x_i^2}\,\mathrm{d}s\nonumber\\
& = \left(-\frac{\partial S}{\partial t} - \|\nabla S\|^2 + \nabla S\cdot\mathbf{a}\right)\mathrm{d}s + \frac{\mu^2}{2}\Delta S\,\mathrm{d}s + \mu\nabla S\cdot\mathrm{d}B_s.\nonumber
\end{align}
Integrating from $0$ to $t$,
\begin{align}
S(Y_t^\mu, 0) - S(Y_0^\mu, t) & = -\int_0^t\left(\frac{\partial S}{\partial t} + \|\nabla S\|^2 - \nabla S\cdot\mathbf{a}\right)\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \frac{\mu^2}{2}\int_0^t\Delta S\,\mathrm{d}s + \mu\int_0^t\nabla S\cdot\mathrm{d}B_s\nonumber
\end{align}
or,
\begin{align}
\frac{1}{\mu}\int_0^t\nabla S\cdot\mathrm{d}B_s & = \frac{1}{\mu^2}(S_0(Y_t^\mu) - S(x, t))\nonumber\\
& \hspace{0.5cm} + \frac{1}{\mu^2}\int_0^t\left(\frac{\partial S}{\partial t} + \|\nabla S\|^2 - \nabla S\cdot\mathbf{a}\right)\mathrm{d}s - \frac{1}{2}\int_0^t\Delta S\,\mathrm{d}s.\nonumber
\end{align}
By the Feynman-Kac formula for this system \eqref{FCF2} and the random change of measure,
\begin{align}
u^\mu(x, t) & = \mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{\mu^2}S_0(Y_t^\mu) + \frac{1}{\mu^2}\int_0^t\bar{V}(Y_s^\mu, t - s)\,\mathrm{d}s\right)M_t\right)\nonumber\\
& = \mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{\mu^2}S_0(Y_t^\mu) + \frac{1}{\mu^2}(S_0(Y_t^\mu) - S(x, t))\right.\right.\nonumber\\
& \hspace{0.5cm} + \frac{1}{\mu^2}\int_0^t\left(\frac{\partial S}{\partial t} + \frac{1}{2}(\|\nabla S\|^2 - 2\nabla S\cdot\mathbf{a} + \|\mathbf{a}\|^2) + V\right)\mathrm{d}s\nonumber\\
& \hspace{0.5cm} - \left.\left.\frac{1}{2}\int_0^t(\Delta S - \nabla\cdot\mathbf{a})\,\mathrm{d}s\right)\right)\nonumber\\
& = \mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{S(x, t)}{\mu^2}\right)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})\,\mathrm{d}s\right.\right.\nonumber\\
& \hspace{0.5cm} + \left.\left.\frac{1}{\mu^2}\int_0^t\left(\frac{\partial S}{\partial t} + \frac{1}{2}\|\nabla S - \mathbf{a}\|^2 + V\right)\mathrm{d}s\right)\right)\nonumber\\
& = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})\,\mathrm{d}s\right)\right).\nonumber
\end{align}
The result follows from this system's Hamilton-Jacobi equation \eqref{HJE2}.

\qedhere
}

\begin{remark}
{
This theorem shows that as long as we have a new process $Y_s^\mu$ with $\nabla S$ replaced with $\nabla S - \mathbf{a}$ in the drift term, then the stochastic elementary formula holds for this system with $\nabla S$ replaced with $\nabla S - \mathbf{a}$.  Reflecting the result of Theorem 12 Part 1 in which the velocity is given by $\nabla S - \mathbf{a}$ rather $\nabla S$.
}
\end{remark}

We can now show that Corollary 1 from the last chapter holds for this system which gives us the behaviour of the new heat equation as $\mu \to 0$.
\corollary
{
Suppose $\nabla S$ is bounded and $\Delta S$ is bounded below, then for $t \in [0, T)$,
$$
\lim_{\mu \to 0}\exp\left(\frac{S(x, t)}{\mu^2}\right)u^\mu(x, t) = T_0(\Phi_t^{-1}(x))\sqrt{|\det D\Phi_t^{-1}(x)|}.
$$
}
\proof
{
The proof is nearly identical to the proof of corollary 1 in the previous chapter.  We want to define a new matrix $S_\mathbf{a}''(s) = (D^2S(y, s) - D\mathbf{a}(y, s))|_{y = \Phi_s(\Phi_t^{-1})}$.  By Theorem 12, the elements of $S_\mathbf{a}''$ are given by,
\begin{align}
& \left.\frac{\partial^2 S}{\partial y_i \partial y_j}(y, s) - \frac{\partial a_j}{\partial y_i}(y, s)\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& \hspace{2cm} = \left.\frac{\partial}{\partial y_i}\left(\frac{\partial S}{\partial y_j}(y, s) - a_j(y, s)\right)\right|_{y = \Phi_s(\Phi_t^{-1}(x))}\nonumber\\
& \hspace{2cm} = \left.\frac{\partial}{\partial y_i}\left(\dot{\Phi}_s(\Phi_s^{-1})(y)\right)_j\right|_{y = \Phi_s(\Phi_t^{-1}(x))}.\nonumber
\end{align}
From here on, by a similar calculation to Theorem 7, we find that $S_\mathbf{a}''$ satisfies the matrix differential equation $S_\mathbf{a}''J(s) = \frac{\mathrm{d}}{\mathrm{d}s}J(s)$, where again $J(s) = D\Phi_s(x)$.  The proof follows by following Corollary 1.

\qedhere
}

Note that the limiting behaviour here is the same as in the previous chapter as long as we replace the old classical mechanical flow map with the relevant map for this sytem.

For the next corollary we would like to introduce the function $v(x, t) = \nabla S(x, t) - \mathbf{a}(x, t)$ in a similar fashion to Chapter 2.  We take the gradient of this system's Hamilton-Jacobi equation \eqref{HJE2},
$$
\frac{\partial v}{\partial t}(x, t) + \frac{\partial \mathbf{a}}{\partial t}(x, t) + \frac{1}{2}\nabla\|v(x, t)\|^2 + \nabla V(x) = \mathbf{0}
$$
and so,
\begin{equation}
\frac{\partial v}{\partial t}(x, t) + \frac{\partial \mathbf{a}}{\partial t}(x, t) + (v(x, t)\cdot\nabla)v(x, t) + v(x, t)\times(\nabla\times v(x, t)) + \nabla V(x) = \mathbf{0} \label{IBE}
\end{equation}
with the initial condition $v(x, 0) = \nabla S_0(x) - \mathbf{a}(x, 0)$.  Our function $v$ satisfies the inviscid Burgers' equation with vorticity.  Again, mimicking Chapter 2, we define $S^\mu(x, t) = -\mu^2\ln u^\mu(x, t)$, then,
\begin{align}
& \frac{\partial S^\mu}{\partial t}(x, t) + \|\nabla S^\mu(x, t) - \mathbf{a}(x, t)\|^2 + V(x)\nonumber\\
= & -\frac{\mu^2}{u^\mu}\frac{\partial u^\mu}{\partial t}(x, t) + \frac{\mu^4}{2(u^\mu)^2}(x, t) + \mu^2\mathbf{a}(x, t)\cdot\frac{\nabla u^\mu}{u^\mu}(x, t) + \frac{1}{2}\|\mathbf{a}(x, t)\|^2 + V(x)\nonumber
\end{align}
by \eqref{VPHE},
\begin{align}
\frac{\partial S^\mu}{\partial t}(x, t) & + \|\nabla S^\mu(x, t) - \mathbf{a}(x, t)\|^2 + V(x)\nonumber\\
= & \frac{\mu^2}{2}\left(\mu^2\frac{\|\nabla u^\mu(x, t)\|^2}{(u^\mu(x, t))^2} - \mu^2\frac{\Delta u^\mu(x, t)}{u^\mu(x, t)} - \nabla\cdot\mathbf{a}(x, t)\right)\nonumber\\
= & \frac{\mu^2}{2}(-\mu^2\Delta\ln u^\mu(x, t) - \nabla\cdot\mathbf{a}(x, t))\nonumber\\
= & \frac{\mu^2}{2}\nabla\cdot(\nabla S(x, t) - \mathbf{a}(x, t)).\nonumber
\end{align}
So, $S^\mu$ satisfies the Hamilton-Jacobi-Bellman equation,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial S^\mu}{\partial t}(x, t) + \|\nabla S^\mu(x, t) - \mathbf{a}(x, t)\|^2 + V(x) = \frac{\mu^2}{2}\nabla\cdot(\nabla S(x, t) - \mathbf{a}(x, t)),\\
& S^\mu(x, 0) = S_0(x) - \mu^2\ln T_0(x).
\end{aligned}
\right.
\end{equation}
Completing what is known as the extended Hopf-Cole transformation\\$v^\mu(x, t) = \nabla S^\mu(x, t) - \mathbf{a}(x, t)$, we find that $v^\mu$ satisfies,
\begin{equation}
\left\{
\begin{aligned}
& \frac{\partial v^\mu}{\partial t}(x, t) + \frac{\partial\mathbf{a}}{\partial t}(x, t) + (v^\mu(x, t)\cdot\nabla)v^\mu(x, t) + v^\mu(x, t)\times(\nabla\times v^\mu(x, t))\\ \label{VBEWV}
& \hspace{0.8cm} = \frac{\mu^2}{2}(\Delta v^\mu(x, t) + \nabla\times\nabla\times\mathbf{a}(x, t)) - \nabla V(x),\\
& v^\mu(x, 0) = \nabla S_0(x) - \mu^2\nabla\ln T_0(x) - \mathbf{a}(x, 0),
\end{aligned}
\right.
\end{equation}
which is known as the viscous Burgers' equation with vorticity.
\corollary
{
Given that the no-caustic condition holds for the caustic time $T$, then under the conditions of Theorem 13 for $t \in [0, T)$,
$$
v^\mu(x, t) = v(x, t) - \mu^2\nabla\ln\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot v(Y_s^\mu, t -s)\,\mathrm{d}s\right)\right)
$$
where $v^\mu$ satisfies the viscous Burgers' equation with vorticity \eqref{VBEWV} and $v$ satisfies the inviscid Burgers' equation with vorticity \eqref{IBE}.
}
\proof
{
We simply take the extended Hopf-Cole transformation of our stochastic elementary formula representation \eqref{SEF2}:
\begin{align}
& \ln u^\mu(x, t)\nonumber\\
& = \ln\exp\left(-\frac{S(x, t)}{\mu^2}\right)\nonumber\\
& \hspace{0.5cm} + \ln\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})(Y_s^\mu, t - s)\,\mathrm{d}s\right)\right)\nonumber\\
& = -\frac{S(x, t)}{\mu^2} + \ln\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})(Y_s^\mu, t - s)\,\mathrm{d}s\right)\right)\nonumber
\end{align}
taking the gradient yields,
\begin{align}
& \nabla\ln u^\mu(x, t) = \nonumber\\
& -\frac{1}{\mu^2}\nabla S(x, t) + \nabla\ln\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})(Y_s^\mu, t - s)\,\mathrm{d}s\right)\right)\nonumber
\end{align}
and completing the transformation,
\begin{align}
-\mu^2\nabla\ln u^\mu & (x, t) - \mathbf{a}(x, t) = \nabla S(x, t) - \mathbf{a}(x, t)\nonumber\\
& - \mu^2\nabla\ln\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot(\nabla S - \mathbf{a})(Y_s^\mu, t - s)\,\mathrm{d}s\right)\right).\nonumber
\end{align}
Hence, remembering $v(x, t) = \nabla S(x, t) - \mathbf{a}(x, t)$, we get,
$$
v^\mu(x, t) = v(x, t) - \mu^2\nabla\ln\mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{2}\int_0^t\nabla\cdot v(Y_s^\mu, t - s)\,\mathrm{d}s\right)\right).
$$

\qedhere
}

We now state and prove our final theorem.
\theorem
{
Given that the no-caustic condition holds for the caustic time $T > 0$, then for $t \in [0, T)$,
$$
u^\mu(x, t) = \exp\left(-\frac{S(x, t)}{\mu^2}\right)\rho_0(x, t)\mathbb{E}\left(\exp\left(\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(Y_s^\mu, t - s)}{\rho_0(Y_s^\mu, t - s)}\,\mathrm{d}s\right)\right)
$$
where, $Y_s^\mu$ satisfies the S.D.E.,
$$
\left\{
\begin{aligned}
\mathrm{d}Y_s^\mu & = (-(\nabla S(Y_s^\mu, t - s) - \mathbf{a}(Y_s^\mu, t - s)) + \mu^2\nabla\ln\rho_0(Y_s^\mu, t - s))\,\mathrm{d}s\\
& \hspace{0.5cm} + \mu\,\mathrm{d}B_s, \hspace{0.3cm} s \in [0, t],\\
Y_0^\mu & = x,
\end{aligned}
\right.
$$
and $\rho_0 = \sqrt{\rho}$.
}
\proof
{
The proof is similar to Theorem 9 but we must remember the new drift.  We again define a general diffusion $Z_s^\mu = -S(Y_s^\mu, t - s) + \mu^2\ln\rho_0(Y_s^\mu, t - s)$ so now our drift becomes $\mathrm{d}Y_s^\mu = (\nabla Z_s^\mu + \mathbf{a})\,\mathrm{d}s + \mu\,\mathrm{d}B_s$.  So by It$\mathrm{\hat{o}}$'s formula,
$$
\mathrm{d}Z_s^\mu = \frac{\partial Z_s^\mu}{\partial s}\,\mathrm{d}s + \sum_{i = 1}^n\frac{\partial Z_s^\mu}{\partial x_i}\,\mathrm{d}Y_s^i + \frac{1}{2}\sum_{i = 1}^n\frac{\partial^2 Z_s^\mu}{\partial x_i \partial x_j}\,\mathrm{d}Y_s^i\,\mathrm{d}Y_s^j
$$
where $\mathrm{d}Y_s^i = \frac{\partial Z_s^\mu}{\partial x_i}\,\mathrm{d}s + a_i\,\mathrm{d}s + \mu\,\mathrm{d}B_s^i$.

As before,
$$
\mathrm{d}Y_s^i\,\mathrm{d}Y_s^j = 0, \hspace{0.3cm} \text{for } i \ne j
$$
and,
$$
\mathrm{d}Y_s^i\,\mathrm{d}Y_s^i = \mu^2\,\mathrm{d}s.
$$
Hence,
\begin{align}
\mathrm{d}Z_s^\mu & = \frac{\partial Z_s^\mu}{\partial s}\,\mathrm{d}s + \sum_{i = 1}^n\frac{\partial Z_s^\mu}{\partial x_i}\frac{\partial Z_s^\mu}{\partial x_i}\,\mathrm{d}s + \sum_{i = 1}^n\frac{\partial Z_s^\mu}{\partial x_i}a_i\,\mathrm{d}s + \frac{\mu^2}{2}\sum_{i = 1}^n\frac{\partial^2Z_s^\mu}{\partial x_i^2}\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \mu\sum_{i = 1}^n\frac{\partial Z_s^\mu}{\partial x_i}\,\mathrm{d}B_s\nonumber
\end{align}
or in vector calculus notation,
$$
\mathrm{d}Z_s^\mu = \left(\frac{\partial Z_s^\mu}{\partial s} + \|Z_s^\mu\|^2 + \nabla Z_s^\mu\cdot\mathbf{a} + \frac{\mu^2}{2}\Delta Z_s^\mu\right)\mathrm{d}s + \mu\nabla Z_s^\mu\cdot\mathrm{d}B_s.
$$
Integrating from $0$ to $t$ and re-arranging gives us,
\begin{align}
-\frac{1}{\mu}\int_0^t\nabla Z_s^\mu\cdot\mathrm{d}B_s & = \frac{1}{\mu^2}(Z_0^\mu - Z_t^\mu) + \frac{1}{2}\int_0^t\Delta Z_s^\mu\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \frac{1}{\mu^2}\int_0^t\left(\frac{\partial Z_s^\mu}{\partial s} + \|Z_s^\mu\|^2 + \nabla Z_s^\mu\cdot\mathbf{a}\right)\mathrm{d}s.\nonumber
\end{align}
Our Radon-Nikodym derivative is given by,
\begin{align}
M_t & = \exp\left(-\frac{1}{\mu}\int_0^t\nabla Z_s^\mu\cdot\mathrm{d}B_s - \frac{1}{\mu^2}\int_0^t\frac{1}{2}\|\nabla Z_s^\mu\|^2\,\mathrm{d}s\right)\nonumber\\
& = \exp\left(\frac{1}{\mu^2}(Z_0^\mu - Z_t^\mu) + \frac{1}{2}\int_0^t\Delta Z_s^\mu\,\mathrm{d}s\right.\nonumber\\
& \hspace{1.5cm} + \left.\frac{1}{\mu^2}\int_0^t\left(\frac{\partial Z_s^\mu}{\partial s} + \frac{1}{2}\|Z_s^\mu\|^2 + \nabla Z_s^\mu\cdot\mathbf{a}\right)\mathrm{d}s\right).\nonumber
\end{align}
We must modify our continuity equation \eqref{CE2} using the definition $\rho = \rho_0^2$,
$$
\frac{\partial\rho_0^2}{\partial t} + \nabla\rho_0^2\cdot(\nabla S - \mathbf{a}) + \rho_0^2\nabla\cdot(\nabla S - \mathbf{a}) = 0
$$
and by vector calculus and re-arranging,
$$
\frac{1}{\rho_0}\frac{\partial\rho_0}{\partial t} + \frac{\nabla\rho_0}{\rho_0}\cdot(\nabla S - \mathbf{a}) + \frac{1}{2}\nabla\cdot(\nabla S - \mathbf{a}) = 0.
$$
We now proceed by direct computation:
$$
\frac{1}{\mu^2}(Z_0^\mu - Z_t^\mu) = \frac{1}{\mu^2}(S_0(Y_t^\mu) - S(x, t)) + \ln\frac{\rho_0(x, t)}{T_0(Y_t^\mu)}
$$
by our modified continuity equation, the definition of $\bar{V}$ and this system's Hamilton-Jacobi equation \eqref{HJE2},
\begin{align}
\frac{1}{\mu^2}&\left(\frac{\partial Z_s^\mu}{\partial s} + \frac{1}{2}\|\nabla Z_s^\mu\|^2 + \nabla Z_s^\mu\cdot\mathbf{a}\right)\nonumber\\
& = \frac{1}{\mu^2}\left(\frac{\partial S}{\partial t} + \frac{1}{2}\|\nabla S\|^2 - \nabla S\cdot\mathbf{a}\right) - \frac{1}{\rho_0}\left(\frac{\partial\rho_0}{\partial t} + \nabla\rho_0\cdot(\nabla S - \mathbf{a})\right)\nonumber\\
& \hspace{0.5cm} + \frac{\mu^2}{2}\frac{\|\nabla\rho_0\|^2}{\rho_0^2}\nonumber\\
& = -\frac{1}{\mu^2}\left(\frac{1}{2}\|\mathbf{a}\|^2 + \frac{\mu^2}{2}\nabla\cdot\mathbf{a} + V\right) + \frac{1}{2}\Delta S + \frac{\mu^2}{2}\frac{\|\nabla\rho_0\|^2}{\rho_0^2}\nonumber\\
& = -\frac{1}{\mu^2}\bar{V} + \frac{1}{2}\Delta S + \frac{\mu^2}{2}\frac{\|\nabla\rho_0\|^2}{\rho_0^2}\nonumber
\end{align}
and by vector calculus,
$$
\frac{1}{2}\Delta Z_s^\mu = -\frac{1}{2}\Delta S - \frac{\mu^2}{2}\frac{\|\nabla\rho_0\|^2}{\rho_0^2} + \frac{\mu^2}{2}\frac{\Delta\rho_0}{\rho_0}
$$
So,
$$
M_t = \exp\left(\frac{1}{\mu^2}(S_0(Y_t^\mu) - S(x, t)) + \ln\frac{\rho_0(x, t)}{T_0(Y_t^\mu)} + \int_0^t\left(-\frac{1}{\mu^2}\bar{V} + \frac{\mu^2}{2}\frac{\Delta\rho_0}{\rho_0}\right)\mathrm{d}s\right)\nonumber
$$
Using the Cameron-Martin change of measure,
\begin{align}
u^\mu(x, t) & = \mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{\mu^2}S_0(Y_t^\mu) + \frac{1}{\mu^2}\int_0^t\bar{V}(Y_t^\mu, t - s)\,\mathrm{d}s\right)M_t\right)\nonumber\\
& = \mathbb{E}\left(T_0(Y_t^\mu)\exp\left(-\frac{1}{\mu^2}S_0(Y_t^\mu) + \frac{1}{\mu^2}\int_0^t\bar{V}(Y_t^\mu, t - s)\,\mathrm{d}s\right.\right.\nonumber\\
& \hspace{0.5cm} + \frac{1}{\mu^2}S_0(Y_t^\mu) - \frac{1}{\mu^2}S(x, t) - \frac{1}{\mu^2}\int_0^t\bar{V}(Y_t^\mu, t - s)\,\mathrm{d}s\nonumber\\
& \hspace{0.5cm} + \left.\left.\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(Y_t^\mu, t - s)}{\rho_0(Y_t^\mu, t - s)}\,\mathrm{d}s\right)\exp\left(\ln\frac{\rho_0(x, t)}{T_0(Y_t^\mu}\right)\right)\nonumber\\
& = \mathbb{E}\left(\rho_0(x, t)\exp\left(-\frac{1}{\mu^2}S(x, t) + \frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(Y_t^\mu, t - s)}{\rho_0(Y_t^\mu, t - s)}\,\mathrm{d}s\right)\right)\nonumber\\
& = \rho_0(x, t)\exp\left(-\frac{S(x, t)}{\mu^2}\right)\mathbb{E}\left(\frac{\mu^2}{2}\int_0^t\frac{\Delta\rho_0(Y_t^\mu, t - s)}{\rho_0(Y_t^\mu, t - s)}\,\mathrm{d}s\right)\nonumber
\end{align}

\qedhere
}

Using Corollary 3 we see that we can obtain a series expansion in higher order terms of $\mu^2$ by using the definition of the exponential function.  So we see that the result of Theorem 9 holds for this new system with a vector potential, again by replacing $\nabla S$ by $\nabla S - \mathbf{a}$ where appropriate.




\begin{thebibliography}{99}

\bibitem{SEF1} K.D. Elworthy and A. Truman - "Classical Mechanics, the Diffusion (Heat) Equation, and the Schr\"{o}dinger Equation on a Riemannian Manifold" in \emph{J. Math. Phys.} $\mathbf{22}$, 2144-2166 (1981).

\bibitem{SEF2} K.D. Elworthy and A. Truman - "The Classical Limit of Quantum Mechanics in a Curved Space Background" in \emph{Functional Integration Theory and Applications} pp. 65-87 (Plenum Press, 1980, New York).

\bibitem{SEF3} A. Truman - "Classical Mechanics, the Diffusion (Heat) Equation, and the Schr\"{o}dinger Equation" in \emph{J. Math. Phys} $\mathbf{18}$, 2308-2315 (1977).

\bibitem{SEF4} K.D. Elworthy and A. Truman - "The Diffusion Equation and Classical Mechanics: An Elementary Formula" in \emph{Stochastic Processes in Quantum Theory and Statistical Physics}, Lecture Notes in Physics Vol. 173 (Springer, 1982, Germany) pp. 136-146.

\bibitem{Freidlin} M. Freidlin - \emph{Functional Integration and Partial Differential Equations} (Princeton University Press, 1985, Princeton, NJ).

\bibitem{ANAT} A. Neate and A. Truman - "Hamilton-Jacobi Theory and the Stochastic Elementary Formula" in \emph{New Trends in Stochastic Analysis and Related Topics}, Vol. 12 (World Scientific, 2012, Singapore) pp. 399-410.

\bibitem{ATHZZ} A. Truman and H. Z. Zhao - "Stochastic Burgers' Equations and their Semi-clasical Expansions" in \emph{Commun. Maths. Phys.} $\mathbf{194}$, 231 pp. 231-248 (1998).

\bibitem{ANSRAT} A. Neate, S. Reasons and A. Truman - "The Stochastic Burgers' Equation with Vorticity: Semiclassical Asymptotic Series Solutions with Applications" in \emph{J. Maths. Phys} $\mathbf{52}$, 083512-1 - 083512-13.

\bibitem{NGDB} N. G. De Bruijn - \emph{Asymptotic Methods in Analysis} (North Holland Publishing Co., 1958, Amsterdam)

\bibitem{PW} M. H. Protter and H. F. Weinberger - \emph{Maximum Principles in Differential Equations} (Prentice-Hall, 1967, Englewood Cliffs, NJ).

\bibitem{Arnol'd} V.I. Arnol'd - \emph{Mathematical Methods of Classical Mechanics} 2$^{\text{nd}}$ Ed. (Springer, 1989, New York).

\bibitem{DW} D. Williams - \emph{Probability with Martingales} (Cambridge University Press, 1991, Cambridge).

\bibitem{Oksendal} B. \O ksendal - \emph{Stochastic Differential Equations: An Introduction with Applications} (Springer, 2005, Berlin).

\end{thebibliography}






\end{document}